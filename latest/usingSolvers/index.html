<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../lambda2.ico">
  
  <title>Solving Linear Equations - Laplacians.jl</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../assets/Laplacians.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Solving Linear Equations";
    var mkdocs_page_input_path = "usingSolvers.md";
    var mkdocs_page_url = "/usingSolvers/index.html";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../index.html" class="icon icon-home"> Laplacians.jl</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../index.html">About</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">User Guide</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Installation/index.html">Installation</a>
                </li>
                <li class="">
                    
    <a class="" href="../Julia/index.html">Using Julia</a>
                </li>
                <li class="">
                    
    <a class="" href="../Examples/index.html">Examples</a>
                </li>
                <li class="">
                    
    <a class="" href="../CSCgraph/index.html">Sparse matrices as graphs</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="index.html">Solving Linear Equations</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#solving-linear-equations-in-laplacians-and-sdd-matrices">Solving linear equations in Laplacians and SDD matrices</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#the-solver-interface">The Solver Interface</a></li>
        
            <li><a class="toctree-l4" href="#cholesky-factorization">Cholesky Factorization</a></li>
        
            <li><a class="toctree-l4" href="#cg-and-pcg">CG and PCG</a></li>
        
            <li><a class="toctree-l4" href="#low-stretch-spanning-trees">Low-Stretch Spanning Trees</a></li>
        
            <li><a class="toctree-l4" href="#augmented-spanning-tree-preconditioners">Augmented Spanning Tree Preconditioners</a></li>
        
            <li><a class="toctree-l4" href="#the-solvers-of-koutis-miller-and-peng">The solvers of Koutis, Miller and Peng.</a></li>
        
            <li><a class="toctree-l4" href="#sampling-solvers-of-kyng-and-sachdeva">Sampling Solvers of Kyng and Sachdeva</a></li>
        
            <li><a class="toctree-l4" href="#algebraic-multigrid">Algebraic Multigrid</a></li>
        
            <li><a class="toctree-l4" href="#solvers-from-matlab">Solvers from Matlab</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../LSST/index.html">Low Stretch Spanning Trees</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Developing</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Developing/index.html">Developing Laplacians</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">API</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../graphGenerators/index.html">generators</a>
                </li>
                <li class="">
                    
    <a class="" href="../operators/index.html">operators</a>
                </li>
                <li class="">
                    
    <a class="" href="../graphUtils/index.html">graphUtils</a>
                </li>
                <li class="">
                    
    <a class="" href="../graphAlgs/index.html">graphAlgs</a>
                </li>
                <li class="">
                    
    <a class="" href="../IO/index.html">IO</a>
                </li>
                <li class="">
                    
    <a class="" href="../solvers/index.html">solvers</a>
                </li>
                <li class="">
                    
    <a class="" href="../sparsification/index.html">sparsification</a>
                </li>
                <li class="">
                    
    <a class="" href="../akpw/index.html">akpw</a>
                </li>
                <li class="">
                    
    <a class="" href="../treeAlgs/index.html">treeAlgs</a>
                </li>
                <li class="">
                    
    <a class="" href="../randTrees/index.html">randTrees</a>
                </li>
                <li class="">
                    
    <a class="" href="../localClustering/index.html">localClustering</a>
                </li>
                <li class="">
                    
    <a class="" href="../privateFuncs/index.html">Private Functions</a>
                </li>
                <li class="">
                    
    <a class="" href="../indexOfAll/index.html">All of the above</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Laplacians.jl</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
    
      
        
          <li>User Guide &raquo;</li>
        
      
    
    <li>Solving Linear Equations</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/danspielman/Laplacians.jl/edit/master/docs/usingSolvers.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <div class="toc">
<ul>
<li><a href="#solving-linear-equations-in-laplacians-and-sdd-matrices">Solving linear equations in Laplacians and SDD matrices</a><ul>
<li><a href="#the-solver-interface">The Solver Interface</a></li>
<li><a href="#cholesky-factorization">Cholesky Factorization</a></li>
<li><a href="#cg-and-pcg">CG and PCG</a></li>
<li><a href="#low-stretch-spanning-trees">Low-Stretch Spanning Trees</a></li>
<li><a href="#augmented-spanning-tree-preconditioners">Augmented Spanning Tree Preconditioners</a></li>
<li><a href="#the-solvers-of-koutis-miller-and-peng">The solvers of Koutis, Miller and Peng.</a></li>
<li><a href="#sampling-solvers-of-kyng-and-sachdeva">Sampling Solvers of Kyng and Sachdeva</a></li>
<li><a href="#algebraic-multigrid">Algebraic Multigrid</a></li>
<li><a href="#solvers-from-matlab">Solvers from Matlab</a><ul>
<li><a href="#incomplete-cholesky-factorizations">Incomplete Cholesky Factorizations</a></li>
<li><a href="#koutiss-combinatorial-multigrid-cmg">Koutis's Combinatorial Multigrid (CMG)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<p><a id='Solving-linear-equations-in-Laplacians-and-SDD-matrices-1'></a></p>
<h1 id="solving-linear-equations-in-laplacians-and-sdd-matrices">Solving linear equations in Laplacians and SDD matrices</h1>
<p>The main purpose of this package is to experiment with the implementation of algorithms for solving systems of linear equations in Laplacian and symmetric, diagonally dominant, M-matrices (SDDM).</p>
<p>At present, the fastest solver in this package for Laplacians is <a href="../solvers/index.html#Laplacians.approxCholLap-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>approxCholLap</code></a>. For SDDM systems, one should use <a href="../solvers/index.html#Laplacians.approxCholSddm"><code>approxCholSddm</code></a>.  Here is a quick demo.  Read more for other solvers and other options you can pass to the solvers.</p>
<pre><code class="julia">julia&gt; a = grid3(50); # an adjacency matrix
julia&gt; la = lap(a); # it's Laplacian
julia&gt; sol = approxCholLap(a); # a solver for la
julia&gt; b = randn(size(la,1)); b = b - mean(b); # a right-hand-side
julia&gt; x = sol(b); # the solution
julia&gt; norm(la*x-b) / norm(b)
5.911931368666469e-7
julia&gt; x = sol(b, tol=1e-12); # a higher accuracy solution
julia&gt; norm(la*x-b) / norm(b)
7.555529748070115e-11
julia&gt; x = sol(b, tol=1e-1, verbose=true); # faster, lower accuracy, with info
PCG stopped after: 0.022 seconds and 3 iterations with relative error 0.07929402690389374.

julia&gt; sddm = copy(la); # doing it with a SDDM matrix
julia&gt; sddm[1,1] += 1;
julia&gt; sol = approxCholSddm(sddm, verbose=true); # solver, with output
Using greedy degree ordering. Factorization time: 0.7143130302429199
Ratio of operator edges to original edges: 2.1120548223350255
ratio of max to min diagonal of laplacian : 6.0
Solver build time: 0.747 seconds.

julia&gt; x = sol(b, verbose=false); # a solve, supressing output
julia&gt; norm(sddm*x - b) / norm(b)
8.739618692868002e-7
</code></pre>

<p>We recall that a matrix $ L $ is a <em>Laplacian</em> matrix if:</p>
<ul>
<li>It is symmetric,</li>
<li>its off-diagonal entries are non-positive, and</li>
<li>all of its row sums are 0.</li>
</ul>
<p>These conditions imply that the diagonal entries are non-negative, and that the matrix is singular.  So, we only hope to solve equations of the form  $ Lx = b $ when $b$ is in the span of the matrix.  When the graph of the nonzero entries of the matrix is connected, this is precisely when the sum of the entries in $ b $ is zero.  Laplacian matrices are always positive semidefinite.</p>
<p>A matrix $ M $ is a symmetric <em>M-matrix</em> if:</p>
<ul>
<li>It is symmetric,</li>
<li>its off-diagonal entries are non-positive, and</li>
<li>it is positive definite.</li>
</ul>
<p>A matrix symmetric $ M $ is <em>diagonally dominant</em> if each of its diagonals is at least the sum of the absolute values of the off-diagonal entries in its row.  A Laplacians matrix is diagonally dominant.  A diagonally dominant matrix is always positive semidefinite.</p>
<p>A <em>SDDM</em> matrix (symmetric, diagonally-dominant M-matrix) is a matrix that is both diagonally dominant and an M-matrix.  You may think of a SDDM matrix as a Laplacian plus a non-negative, non-zero, diagonal matrix.  However, this is only guaranteed to produce a SDDM matrix when the graph underlying the Laplacian is connected.</p>
<p>Laplacians.jl contains code for solving systems of linear equations in both Laplacian and SDDM matrices.  In fact, these problems are equivalent.  So, usually a solver for one type of system is implemented, and then wrapped to solve the other. The same ideas can be used to solve systems of equations in SDD matrices (the off-diagonals can be positive or negative), but a wrapper for these has not yet been written.</p>
<p><a id='The-Solver-Interface-1'></a></p>
<h2 id="the-solver-interface">The Solver Interface</h2>
<p>All of the SDDM solvers take the SDDM matrix as input.</p>
<p><em>All of the Laplacian solvers take the adjacency matrix of the underlying graph as input.</em></p>
<p>To solve a system of linear equations, one first passes the matrix defining the system to a linear equation solving algorithm.  This will return a function that solves systems of linear equations in that matrix.  For example,</p>
<pre><code class="julia">julia&gt; n = 1000;
julia&gt; a = wtedChimera(n);  # produces a graph, as a sparse adjacency matrix
julia&gt; b = randn(n); 
julia&gt; b = b - mean(b); # so there is a solution
julia&gt; f = cholLap(a)
(::#79) (generic function with 1 method)
julia&gt; x = f(b);
julia&gt; la = lap(a);  # construct the Laplacian of a
julia&gt; norm(la*x-b)
2.9565023548855584e-13
</code></pre>

<p>All of the solvers take the following keyword arguments. This means that they are optional, and will be set to their default values if not specified.</p>
<ul>
<li><code>tol</code> : the relative accuracy required: $ | M x - b | / | b | $.</li>
<li><code>maxits</code> : the maximum number of iterations, for iterative algorithms.</li>
<li><code>maxtime</code> : quit if it takes more than this many seconds.  Not all routines obey this, but they try.</li>
<li><code>verbose</code> : set to <code>true</code> to display diagnostic information.</li>
<li><code>pcgIts</code> : If the algorithm is iterative, this allows it to return the number of iterations it performed.  If <code>pcgIts</code> is an array of positive length, then its first entry is set to the number of iterations.  Where <code>verbose</code> prints this information, <code>pcgIts</code> allows it to be returned to other code.  To disable this set <code>pcgIts</code> to a zero length array, like <code>Int[]</code>.</li>
</ul>
<p>Most of the solvers are iterative, exploiting the preconditioned conjugate gradient. These are the solvers for which <code>maxits</code>, <code>maxtime</code> and <code>pcgIts</code> make the most sense.  Some solvers, like Cholesky factorization, just ignore these parameters.</p>
<p>All of these parameters may be set in the call that constructs <code>f</code>.  They may then be over-ridden by again setting them in the call to <code>f</code>. Let's see how this works when using the conjugate gradient.</p>
<pre><code class="julia">julia&gt; f = cgLapSolver(a, tol=1e-2, verbose=true)
(::f) (generic function with 1 method)
julia&gt; x = f(b);
CG BLAS stopped after: 78 iterations with relative error 0.009590493139133275.
julia&gt; norm(la*x-b)/norm(b)
0.00959049313913375

julia&gt; pcgIts = [0]
1-element Array{Int64,1}:
 0
julia&gt; x = f(b,verbose=false, pcgIts=pcgIts);
julia&gt; pcgIts
1-element Array{Int64,1}:
 78

julia&gt; x = f(b,verbose=true, maxits=50);
CG BLAS stopped after: 50 iterations with relative error 0.050483096216933886.

julia&gt; x = f(b, tol=1e-4);
CG BLAS stopped after: 131 iterations with relative error 8.886882933346416e-5.
julia&gt; norm(la*x-b)/norm(b)
8.886882933294668e-5
</code></pre>

<p>For some experiments with solvers, including some of those below, look at the notebook Solvers.ipynb.</p>
<p>In the following, we document many of the solvers that have been implemented in this package.</p>
<p><a id='Cholesky-Factorization-1'></a></p>
<h2 id="cholesky-factorization">Cholesky Factorization</h2>
<p>Cholesky factorization, the version of Gaussian Elimination for symmetric matrices, should be the first solver you try.  It will be very fast for matrices of dimension less than 1000, and for larger matrices coming from two-dimensional problems.</p>
<p>You can compute a cholesky factor directly with <code>cholfact</code>.  It does  more than just compute the factor, and it saves its result in a data structure that implements <code>\</code>.  It uses SuiteSparse by Tim Davis.</p>
<p>Here is an example of how you would use it to solve a general non-singular linear system.</p>
<pre><code class="julia">a = grid2(5)
la = lap(a)
sddm = copy(la)
sddm[1,1] = sddm[1,1] + 1
F = cholfact(sddm)

n = size(a)[1]
b = randn(n)
x = F \ b
norm(sddm*x-b)

    1.0598778281116327e-14
</code></pre>

<p>As <code>cholfact</code> does not satisfy our interface, we wrap it in a routine <a href="../solvers/index.html#Laplacians.cholSDDM"><code>cholSDDM</code></a> that does.</p>
<p>To solve systems in Laplacian matrices, use <a href="../solvers/index.html#Laplacians.cholLap"><code>cholLap</code></a>.  Recall that this routine should be passed the adjacency matrix.</p>
<pre><code class="julia">f = cholLap(a)
b = randn(n); 
b = b - mean(b);
norm(la*f(b) - b)
    2.0971536951312585e-15
</code></pre>

<p><a id='CG-and-PCG-1'></a></p>
<h2 id="cg-and-pcg">CG and PCG</h2>
<p>We have written implementations of Conjugate Gradient (CG) and Preconditioned Conjugate Gradient (PCG) that satisfy the interface. These routines use BLAS when possible, and slower routines when dealing with data types that BLAS cannot handle.  </p>
<pre><code class="julia">srand(1)
n = 50
M = randn(n,n); M = M * M';
b = randn(n)
x = cg(M,b,maxits=100,verbose=true);
CG BLAS stopped after: 66 iterations with relative error 2.0166243927814765e-7.

bbig = convert(Array{BigFloat,1},b)
xbig = cg(M,bbig,maxits=100,tol=1e-30)
CG Slow stopped after: 50 iterations with relative error 2.18672511297479336887519117065525148757254642683072581090418060286711737398731e-38.

norm(M*xbig - bbig)
1.605742093628722039938504001423963138146137896744531914963345296279741402982296e-37
</code></pre>

<p>To create a function <code>f</code> that uses cg to solve systems in M, use <a href="../solvers/index.html#Laplacians.cgSolver"><code>cgSolver</code></a>.  For Laplacians, use <a href="../solvers/index.html#Laplacians.cgLapSolver-Tuple{SparseMatrixCSC}"><code>cgLapSolver</code></a>.</p>
<pre><code class="julia">julia&gt; n = 1000;
julia&gt; a = wtedChimera(n,1);
julia&gt; f = Laplacians.cgLapSolver(a,maxits=100);

julia&gt; b = randn(n);
julia&gt; b = b - mean(b);
julia&gt; x = f(b,verbose=true);
CG BLAS stopped after: 100 iterations with relative error 0.012102058751548373.


julia&gt; la = lap(a);
julia&gt; sddm = copy(la);
julia&gt; sddm = sddm + spdiagm(rand(n)/100);
julia&gt; g = cgSolver(sddm,verbose=true)
(::f) (generic function with 1 method)

julia&gt; x = g(b);
CG BLAS stopped after: 253 iterations with relative error 7.860172210007891e-7.
</code></pre>

<p>PCG also takes as input a preconditioner.  This should be a function.  Here is an example of how one might construct and use a diagonal preonditioner.  To motivate this, I will use a grid with highly varying weights on edges.</p>
<pre><code class="julia">srand(1)
a = mapweight(grid2(200),x-&gt;1/(rand(1)[1]));
la = lap(a)
n = size(la)[1]
b = randn(n)
b = b - mean(b);

d = diag(la)
prec(x) = x ./ d
@time x = pcg(la,b,prec,maxtime=1,tol=1e-2,verbose=true);

PCG BLAS stopped at maxtime.
PCG BLAS stopped after: 530 iterations with relative error 0.07732478003311881.
  1.007756 seconds (10.32 k allocations: 648.525 MB, 9.69% gc time)

@time x = pcg(la,b,prec,maxtime=3,tol=1e-2,verbose=true);
PCG BLAS stopped after: 1019 iterations with relative error 0.009984013184429813.
  2.086828 seconds (19.57 k allocations: 1.216 GB, 9.92% gc time) 
</code></pre>

<p>Without the preconditioner, CG takes much longer on this example.</p>
<pre><code class="julia">@time x = cg(la,b,tol=1e-2,maxtime=10,verbose=true);

CG BLAS stopped at maxtime.
CG BLAS stopped after: 8879 iterations with relative error 0.054355534834831624.
 10.001998 seconds (97.91 k allocations: 2.649 GB, 4.48% gc time)
</code></pre>

<p><a href="../solvers/index.html#Laplacians.pcgSolver"><code>pcgSolver</code></a> creates a function that uses the preconditioner to solve systems in the matrix.</p>
<pre><code class="julia">f = pcgSolver(la,prec)
@time x = f(b,maxtime=3,tol=1e-2,verbose=true);
PCG BLAS stopped after: 1019 iterations with relative error 0.009984013184429813.
  1.892217 seconds (19.58 k allocations: 1.216 GB, 9.47% gc time)
</code></pre>

<p><a href="../solvers/index.html#Laplacians.pcgLapSolver-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>pcgLapSolver</code></a> uses the Laplacian of one matrix as a preconditioner for the first.  It solves systems of linear equations in the preconditioner by Cholesky factorization.  It performs the Cholesky factorization when <a href="../solvers/index.html#Laplacians.pcgLapSolver-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>pcgLapSolver</code></a> is called.  This is why we do the work of creating <code>f</code> only once.  Here is an example using a Low-Stretch Spanning Tree preconditioner.</p>
<pre><code class="julia">@time t = akpw(a)
  0.210467 seconds (1.43 M allocations: 91.226 MB, 19.23% gc time)

@time f = pcgLapSolver(a,t)
  0.160210 seconds (288 allocations: 28.076 MB, 72.28% gc time)

@time x = f(b,maxtime=3,tol=1e-2,verbose=true);
PCG BLAS stopped after: 260 iterations with relative error 0.009864463201800925.
  1.014897 seconds (28.02 k allocations: 1.008 GB, 9.81% gc time)
</code></pre>

<p><a id='Low-Stretch-Spanning-Trees-1'></a></p>
<h2 id="low-stretch-spanning-trees">Low-Stretch Spanning Trees</h2>
<p>In order to make preconditioners, we will want low-stretch spanning trees.  We do not yet have any code that is guaranteed to produce these.  Instead, we supply three heuristics: <a href="../akpw/index.html#Laplacians.akpw-Tuple{Any}"><code>akpw</code></a> which is inspired by the algorith of Alon, Karp, Peleg and West, and  randomized versions of Prim and Kruskal's algorithm. <a href="../randTrees/index.html#Laplacians.randishKruskal-Tuple{SparseMatrixCSC}"><code>randishKruskal</code></a> samples the remaining edges with probability proportional to their weight.  <a href="../randTrees/index.html#Laplacians.randishPrim-Union{Tuple{SparseMatrixCSC{Tval,Tind}}, Tuple{Tind}, Tuple{Tval}} where Tind where Tval"><code>randishPrim</code></a> samples edges on the boundary while using the same rule.  We recommend using <a href="../akpw/index.html#Laplacians.akpw-Tuple{Any}"><code>akpw</code></a>.</p>
<p>See <a href="../LSST/index.html">Low Stretch Spanning Trees</a> to learn more about these.</p>
<p><a id='Augmented-Spanning-Tree-Preconditioners-1'></a></p>
<h2 id="augmented-spanning-tree-preconditioners">Augmented Spanning Tree Preconditioners</h2>
<p>These are obtained by constructing a spanning tree of a graph, and then adding back some more edges from the graph.  The tree should have low stretch.  The edges to add back are chosen at random with probabilities proportional to their stretches.</p>
<p>These are implemented in the routines</p>
<ul>
<li><a href="../solvers/index.html#Laplacians.augTreeSddm-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>augTreeSddm</code></a>, for SDDM matrices</li>
<li><a href="../solvers/index.html#Laplacians.augTreeLap-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>augTreeLap</code></a></li>
<li><a href="../solvers/index.html#Laplacians.augTreePrecon-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>augTreePrecon</code></a></li>
<li><a href="../solvers/index.html#Laplacians.augmentTree-Union{Tuple{SparseMatrixCSC{Tv,Ti},SparseMatrixCSC{Tv,Ti},Ti}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>augmentTree</code></a></li>
</ul>
<p><a id='The-solvers-of-Koutis,-Miller-and-Peng.-1'></a></p>
<h2 id="the-solvers-of-koutis-miller-and-peng">The solvers of Koutis, Miller and Peng.</h2>
<p>Solvers inspired by the algorithm from "Approaching optimality for solving SDD systems" by Koutis, Miller, and Peng, <i>SIAM Journal on Computing</i>, 2014.</p>
<ul>
<li><a href="../solvers/index.html#Laplacians.KMPLapSolver-Tuple{Any}"><code>KMPLapSolver</code></a></li>
<li><a href="../solvers/index.html#Laplacians.KMPSDDMSolver-Tuple{Any}"><code>KMPSDDMSolver</code></a></li>
</ul>
<p><a id='Sampling-Solvers-of-Kyng-and-Sachdeva-1'></a></p>
<h2 id="sampling-solvers-of-kyng-and-sachdeva">Sampling Solvers of Kyng and Sachdeva</h2>
<p>These are inspired by the paper "Approximate Gaussian Elimination for Laplacians: Fast, Sparse, and Simple" by Rasmus Kyng and Sushant Sachdeva, FOCS 2016. </p>
<p>These first two follow that paper reasonably closely.</p>
<ul>
<li><a href="../solvers/index.html#Laplacians.samplingSDDMSolver-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>samplingSDDMSolver</code></a></li>
<li><a href="../solvers/index.html#Laplacians.samplingLapSolver-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>samplingLapSolver</code></a></li>
</ul>
<p>The following is a modification of the algorithm that eliminates edges one at a time.  The code is by Daniel Spielman.  The algorithm has not yet been analyzed.  It is presently the fastest in this package.</p>
<ul>
<li><a href="../solvers/index.html#Laplacians.approxCholLap-Union{Tuple{SparseMatrixCSC{Tv,Ti}}, Tuple{Ti}, Tuple{Tv}} where Ti where Tv"><code>approxCholLap</code></a></li>
</ul>
<p><a id='Algebraic-Multigrid-1'></a></p>
<h2 id="algebraic-multigrid">Algebraic Multigrid</h2>
<p>This is an interface to the algebraic multigrid solvers from the PyAMG package.</p>
<ul>
<li><a href="../@ref"><code>AMGLapSolver</code></a></li>
<li><a href="../@ref"><code>AMGSolver</code></a>, for SDDM systems.</li>
</ul>
<p><a id='Solvers-from-Matlab-1'></a></p>
<h2 id="solvers-from-matlab">Solvers from Matlab</h2>
<p>The <a href="https://github.com/JuliaInterop/MATLAB.jl">MATLAB.jl</a> package allows Julia to call routines from Matlab, provided you have Matlab installed.  It does this in a very efficient fashion: it starts up the Matlab process when you type <code>using MATLAB</code>, and then communicates with it.  So, we have wrapped some solvers from Matlab so that they obey the same interface.</p>
<p>These are not part of the Laplacians module, but are included in the package under <code>src/matlabSolvers.jl</code>.  To include them, type</p>
<pre><code class="julia">include(string(Pkg.dir(&quot;Laplacians&quot;) , &quot;/src/matlabSolvers.jl&quot;))
</code></pre>

<p>We provide the docstrings for these here.</p>
<p><a id='Incomplete-Cholesky-Factorizations-1'></a></p>
<h3 id="incomplete-cholesky-factorizations">Incomplete Cholesky Factorizations</h3>
<p>These use the no-fill incomplete Cholesky factorizations implemented in Matlab.  They first order the vertices by the <code>symrcm</code> ordering.</p>
<p>The solvers are:</p>
<ul>
<li><code>f = matlab_ichol_sddm(sddm; tol, maxtime, maxits, pctIts, verbose)</code></li>
<li><code>f = matlab_ichol_lap(A; tol, maxtime, maxits, pctIts, verbose)</code></li>
</ul>
<p>A routine that just wraps the function that solves equations in the preconditioner is provided as well:</p>
<ul>
<li><code>f = matlab_ichol(sddm)</code></li>
</ul>
<p><a id='Koutis's-Combinatorial-Multigrid-(CMG)-1'></a></p>
<h3 id="koutiss-combinatorial-multigrid-cmg">Koutis's Combinatorial Multigrid (CMG)</h3>
<p>You must have installed Yiannis Koutis's <a href="http://www.cs.cmu.edu/~jkoutis/cmg.html">Combinatorial Multigrid Code</a>, and it must be on Matlab's default path.  As this code returns a function rather than a preconditioner, it would be inefficient to make it use our PCG code and satisfy our interface.  So, it does not.</p>
<ul>
<li><code>x = matlabCmgSolver(mat, b; tol::Real=1e-6, maxits=10000)</code></li>
</ul>
<p>The matrix <code>mat</code> can either be SDDM or a Laplacian.  This solves the system in <code>b</code>.</p>
<p>If you need to specify the solver separately from <code>b</code>, you can call</p>
<ul>
<li><code>x = matlabCmgSolver(mat; tol::Real=1e-6, maxits=10000)</code></li>
</ul>
<p>or, for the Laplacians of the adjacency matrix <code>A</code>,</p>
<ul>
<li><code>x = matlabCmgLap(A; tol::Real=1e-6, maxits=10000)</code></li>
</ul>
<p>However, this does not create the solver.  It merely returns a call to the previous routine.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../LSST/index.html" class="btn btn-neutral float-right" title="Low Stretch Spanning Trees">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../CSCgraph/index.html" class="btn btn-neutral" title="Sparse matrices as graphs"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/danspielman/Laplacians.jl/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../CSCgraph/index.html" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../LSST/index.html" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../assets/mathjaxhelper.js"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
