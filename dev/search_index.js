var documenterSearchIndex = {"docs":
[{"location":"Julia/#Using-Julia-1","page":"Using Julia","title":"Using Julia","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"These are some things you might want to know about using Julia if it is new to you.  There are now many other resources that can explain Julia to you.  But, we keep this section here for reference.","category":"page"},{"location":"Julia/#Docstrings-1","page":"Using Julia","title":"Docstrings","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"Julia 0.5 lets you take advantage of docstrings. For example, ?ringGraph produces","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"The simple ring on n vertices","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"When having a multiline comment, make sure that lines don't have starting and trailing spaces. This will mess up the indentation when calling '?func_name'.","category":"page"},{"location":"Julia/#Julia-Notebooks-1","page":"Using Julia","title":"Julia Notebooks","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"To get the Julia notebooks working, I presently type jupyter notebook. I then select the kernel to be Julia-0.5.0. It seems important to run this command from a directory that contains all the directories that have notebooks that you will use.  In particular, I advise against \"uploading\" notebooks from other directories.  That has only given me trouble.","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"To turn a notebook into html, you type something like","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"jupyter nbconvert Laplacians.ipynb","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"or","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"jupyter nbconvert --to markdown --stdout Sampler.ipynb > SamplerNotebook.md","category":"page"},{"location":"Julia/#Workflows-1","page":"Using Julia","title":"Workflows","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"Julia has an IDE called Juno.  Both Dan and Serban have encountered some trouble with it: we have both found that it sometimes refuses to reload .jl code that we have written.  Please document workflows that you have found useful here:","category":"page"},{"location":"Julia/#Dan's-current-workflow:-1","page":"Using Julia","title":"Dan's current workflow:","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"I use emacs (which has a mode for Julia) and the notebooks.\nI develop Julia code in a \"temporary\" file with a name like develX.jl.  While I am developing, this code is not included by the module to which it will eventually belong.\nAfter modifying code, I reload it with include(\"develX.jl\").  This works fine for reloading methods.  It is not a good way to reload modules or types.  So, I usually put the types either in a separate file, or in my julia notebook.\nI am writing this documention in MacDown.","category":"page"},{"location":"Julia/#Add-your-current-workflow-here:-1","page":"Using Julia","title":"Add your current workflow here:","text":"","category":"section"},{"location":"Julia/#Things-to-be-careful-of-(common-bugs)-1","page":"Using Julia","title":"Things to be careful of (common bugs)","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"Julia passes vectors and matrices to routines by reference, rather than by copying them.  If you type x = y when x and y are arrays, then this will make x a pointer to y.  If you want x to be a copy of y, type x = copy(y).  This can really mess up matlab programmers.  I wrote many functions that were modifying their arguments without realizing it.\nOn the other hand, if you type x = x + y, then x becomes a newly allocated vector and no longer refers to the original.  This is true even if you type x += y.  Here is an example that shows two of the possible behaviors, and the difference between what happens inside functions.","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"\n\"Adds b in to a\"\nfunction addA2B(a,b)\n    for i in 1:length(a)\n        a[i] += b[i]\n    end\nend\n\n\"Fails to add b in to a\"\nfunction addA2Bfail(a,b)\n\ta += b\nend\n\na = [1 0]\nb = [2 2]\naddA2B(a,b)\na\n\n1x2 Array{Int64,2}:\n 3  2\n\na = [1 0]\nb = [2 2]\naddA2Bfail(a,b)\na\n\n1x2 Array{Int64,2}:\n 1  0\n\na += b\na\n\n1x2 Array{Int64,2}:\n 3  2\n","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"If you are used to programming in Matlab, you might be tempted to type a line like for i in 1:10,.  Do not put extra commas in Julia!  It will cause bad things to happen.\nTo get a vector with entries 1 through n, type collect(1:n).  The object 1:n is a range, rather than a vector.\nJulia sparse matrix entries dissapear if they are set to 0. In order to overcome this, use the setValue function. setValue(G, u, i, 0) will set weighti(G, u, i) to 0 while also leaving (u, nbri(G, u, i)) in the matrix.  Note This problem may have been fixed with Julia version 0.5.","category":"page"},{"location":"Julia/#Useful-Julia-functions-1","page":"Using Julia","title":"Useful Julia functions","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"I am going to make a short list of Julia functions/features that I find useful.  Please add those that you use often as well.","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"docstrings: in the above example, I used a docstring to document each function.  You can get these by typing ?addA2B.  You can also  write longer docstrings and use markdown.  I suggest putting them in front of every function.\nmethods(foo) lists all methods with the name foo.\nfieldnames(footype) tells you all the fields of footype.  Note that this is 0.4.  In 0.3.11, you type names(footype)","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"julia> a = sparse(rand(3,3));\njulia> fieldnames(a)\n5-element Array{Symbol,1}:\n :m\n :n\n :colptr\n :rowval\n :nzval","category":"page"},{"location":"Julia/#Optimizing-code-in-Julia-1","page":"Using Julia","title":"Optimizing code in Julia","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"The best way that I've found of figuring out what's slowing down my code has been to use @code_warntype.  ","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"Note that the first time you run a piece of code in Julia, it gets compiled.  So, you should run it on a small example before trying to time it.  Then, use @time to time your code.","category":"page"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"I recommend reading the Performance Tips in the Julia documentation, not that I've understood all of it yet.","category":"page"},{"location":"Julia/#How-should-notebooks-play-with-Git?-1","page":"Using Julia","title":"How should notebooks play with Git?","text":"","category":"section"},{"location":"Julia/#","page":"Using Julia","title":"Using Julia","text":"The great thing about the notebooks is that they contain live code, so that you can play with them.  But, sometimes you get a version that serves as great documentation, and you don't want to klobber it my mistake later (or evern worse, have someone else klobber it).  Presumably if someone accidently commits a messed up version we can unwind that.  But, is there a good way to keep track of this?","category":"page"},{"location":"randTrees/#randTrees-1","page":"randTrees","title":"randTrees","text":"","category":"section"},{"location":"randTrees/#","page":"randTrees","title":"randTrees","text":"Order = [:type, :function]\nPages   = [\"randTrees.md\"]","category":"page"},{"location":"randTrees/#","page":"randTrees","title":"randTrees","text":"Modules = [Laplacians]\nPages   = [\"randTrees.jl\"]\nPrivate = false","category":"page"},{"location":"randTrees/#Laplacians.randishKruskal-Tuple{SparseArrays.SparseMatrixCSC}","page":"randTrees","title":"Laplacians.randishKruskal","text":"tree = randishKruskal(A)\n\nA heuristic for computing low-stretch spanning trees.  Where Kruskal's MST algorithm adds edges in order of weight, this algorithm adds them at random with probability proportional to their weight.\n\n\n\n\n\n","category":"method"},{"location":"randTrees/#Laplacians.randishPrim-Union{Tuple{SparseArrays.SparseMatrixCSC{Tval, Tind}}, Tuple{Tind}, Tuple{Tval}} where {Tval, Tind}","page":"randTrees","title":"Laplacians.randishPrim","text":"tree = randishPrim(A)\n\nA heuristic for computing low-stretch spanning trees.  Where Prim's MST algorithm grows a cluster by always adding the edge on the boundary of maximum weight, this algorithm adds a boundary edge with probability proportional to its weight.\n\n\n\n\n\n","category":"method"},{"location":"sparsification/#sparsification-1","page":"sparsification","title":"sparsification","text":"","category":"section"},{"location":"sparsification/#","page":"sparsification","title":"sparsification","text":"Order = [:type, :function]\nPages   = [\"sparsification.md\"]","category":"page"},{"location":"sparsification/#","page":"sparsification","title":"sparsification","text":"Modules = [Laplacians]\nPages   = [\"sparsify.jl\",\"conditionNumber.jl\"]\nPrivate = false","category":"page"},{"location":"sparsification/#Laplacians.sparsify-Tuple{Any}","page":"sparsification","title":"Laplacians.sparsify","text":"as = sparsify(a; ep=0.5)\n\nApply Spielman-Srivastava sparsification: sampling by effective resistances. ep should be less than 1.\n\n\n\n\n\n","category":"method"},{"location":"sparsification/#Laplacians.approxQual-Tuple{Any, Any}","page":"sparsification","title":"Laplacians.approxQual","text":"eps = approxQual(graph1, graph2; tol=1e-5, verbose=false)\n\nComputes the eps for which graph1 and graph2 are eps approximations of each other. That is, L1 <= (1+eps) L2, and vice versa.\n\nIt is randomized, so you might want to run it again if you don't trust the answers.\n\n\n\n\n\n","category":"method"},{"location":"sparsification/#Laplacians.conditionNumber-Tuple{SparseArrays.SparseMatrixCSC, Function}","page":"sparsification","title":"Laplacians.conditionNumber","text":"kappa = conditionNumber(graph, precon; tol=1e-5, verbose=false)\n\nComputes the relative condition number of graph and a preconditioning function.\n\nIt is randomized, so you might want to run it again if you don't trust the answers.\n\n\n\n\n\n","category":"method"},{"location":"sparsification/#Laplacians.conditionNumber-Tuple{SparseArrays.SparseMatrixCSC, SparseArrays.SparseMatrixCSC}","page":"sparsification","title":"Laplacians.conditionNumber","text":"kapps = conditionNumber(graph1, graph2; tol=1e-5, verbose=false)\n\nComputes the relative condition number of graph1 and graph2.\n\nIt is randomized, so you might want to run it again if you don't trust the answers.\n\n\n\n\n\n","category":"method"},{"location":"sparsification/#Laplacians.support-Tuple{Any, Any}","page":"sparsification","title":"Laplacians.support","text":"sup12, sup21 = support(graph1, graph2; tol=1e-5)\n\nComputes the support of graph1 wrt graph2, and the other way around. It is randomized, so you might want to run it again if you don't trust the answers.\n\n\n\n\n\n","category":"method"},{"location":"indexOfAll/#Index-of-all-exported-1","page":"All of the above","title":"Index of all exported","text":"","category":"section"},{"location":"indexOfAll/#","page":"All of the above","title":"All of the above","text":"This is an index of all the exported methods. We would include the docstrings, but Documenter.jl does not let us.","category":"page"},{"location":"indexOfAll/#","page":"All of the above","title":"All of the above","text":"modules = [Laplacians]","category":"page"},{"location":"CSCgraph/#Using-sparse-matrices-as-graphs-1","page":"Sparse matrices as graphs","title":"Using sparse matrices as graphs","text":"","category":"section"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"The routines deg, nbri and weighti will let you treat a sparse matrix like a graph.","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"deg(graph, u) is the degree of node u. nbri(graph, u, i) is the ith neighbor of node u. weighti(graph, u, i) is the weight of the edge to the ith neighbor of node u.","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"Note that we start indexing from 1.","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"For example, to iterate over the neighbors of node v,   and play with the attached nodes, you could write code like:","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"  for i in 1:deg(mat, v)\n     nbr = nbri(mat, v, i)\n     wt = weighti(mat, v, i)\n     foo(v, nbr, wt)\n  end","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"But, this turns out to be much slower than working with the structure directly, like","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"  for ind in mat.colptr[v]:(mat.colptr[v+1]-1)\n      nbr = mat.rowval[ind]\n      wt = mat.nzval[ind]\n      foo(v, nbr, wt)\n  end","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"[ ] Maybe we can make a macro to replace those functions.  It could be faster and more readable.","category":"page"},{"location":"CSCgraph/#The-SparseMatrixCSC-data-structure-1","page":"Sparse matrices as graphs","title":"The SparseMatrixCSC data structure","text":"","category":"section"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"You can explore what is going on with the data structure by looking at some examples.  For example, here is a randomly weighted complete graph on 4 vertices, first displayed as a matrix:","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"gr = round(10*uniformWeight(completeGraph(4)))\n\n4x4 sparse matrix with 12 Float64 entries:\n\t[2, 1]  =  3.0\n\t[3, 1]  =  3.0\n\t[4, 1]  =  6.0\n\t[1, 2]  =  3.0\n\t[3, 2]  =  1.0\n\t[4, 2]  =  2.0\n\t[1, 3]  =  3.0\n\t[2, 3]  =  1.0\n\t[4, 3]  =  7.0\n\t[1, 4]  =  6.0\n\t[2, 4]  =  2.0\n\t[3, 4]  =  7.0\n\t\nfull(gr)\n\n4x4 Array{Float64,2}:\n 0.0  3.0  3.0  6.0\n 3.0  0.0  1.0  2.0\n 3.0  1.0  0.0  7.0\n 6.0  2.0  7.0  0.0","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"To see the underlying data structure, use fieldnames.","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"fieldnames(gr)\n\n5-element Array{Symbol,1}:\n :m     \n :n     \n :colptr\n :rowval\n :nzval ","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"m and n are the dimensions of the matrix. The entries of the matrix are stored in nzval. colptr[i] is the index in nzval of the first nonzero entry in column i.  rowval tells you which rows in each column are nonzero. The indices of the nonzero entries in column i are stored in  rowval[colptr[i]] through rowval[colptr[i+1]-1].","category":"page"},{"location":"CSCgraph/#","page":"Sparse matrices as graphs","title":"Sparse matrices as graphs","text":"gr.colptr \n\n5-element Array{Int64,1}:\n  1\n  4\n  7\n 10\n 13\n \n [gr.rowval gr.nzval]\n \n 12x2 Array{Float64,2}:\n 2.0  3.0\n 3.0  3.0\n 4.0  6.0\n 1.0  3.0\n 3.0  1.0\n 4.0  2.0\n 1.0  3.0\n 2.0  1.0\n 4.0  7.0\n 1.0  6.0\n 2.0  2.0\n 3.0  7.0","category":"page"},{"location":"Examples/#Examples-1","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"Examples/#","page":"Examples","title":"Examples","text":"The following are links to html files of Julia notebooks. These notebooks are also in the notebook directory, and can be open there so that you can run the code live. You should be able to find them under ~/.julia/v0.4/Laplacians/notebooks.","category":"page"},{"location":"Examples/#","page":"Examples","title":"Examples","text":"FirstNotebook\nSolvers\nSampler\nLocalClustering\nLocalClustering Statistics","category":"page"},{"location":"Laplacians/#Laplacians-1","page":"Laplacians","title":"Laplacians","text":"","category":"section"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"To see if it is working, try something like this:","category":"page"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"a = chimera(100,6)\nspectral_drawing(a)","category":"page"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"or","category":"page"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"a = generalizedNecklace(grid2(6),grid2(3),2)\nspectral_drawing(a)","category":"page"},{"location":"Laplacians/#To-use-Laplacians-1","page":"Laplacians","title":"To use Laplacians","text":"","category":"section"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"Examples of how to do many things in yinsGraph may be found in the IJulia notebooks.  These have the extensions .ipynb.  When they look nice, I think it makes sense to convert them to .html.","category":"page"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"Right now, the notebooks worth looking at are:","category":"page"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"yinsGraph - usage, demo, and speed tests (Laplacians was previously called yinsGraph)\nSolvers - code for solving equations.  How to use direct methods, conjugate gradient, and a preconditioned augmented spanning tree solver.","category":"page"},{"location":"Laplacians/#","page":"Laplacians","title":"Laplacians","text":"(I suggest that you open the html in your browser)","category":"page"},{"location":"treeAlgs/#Tree-Algorithms-1","page":"treeAlgs","title":"Tree Algorithms","text":"","category":"section"},{"location":"treeAlgs/#","page":"treeAlgs","title":"treeAlgs","text":"Order = [:type, :function]\nPages   = [\"treeAlgs.md\"]","category":"page"},{"location":"treeAlgs/#","page":"treeAlgs","title":"treeAlgs","text":"Modules = [Laplacians]\nPages   = [\"treeAlgs.jl\"]\nPrivate = false","category":"page"},{"location":"treeAlgs/#Laplacians.comp_stretches-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, SparseArrays.SparseMatrixCSC{Tv, Ti}}} where {Tv, Ti}","page":"treeAlgs","title":"Laplacians.comp_stretches","text":"Compute the stretched of every edge in mat with respect to the tree tree. Returns the answer as a sparse matrix with the same nonzero structure as mat. Assumes that mat is symmetric. tree should be the adjacency matrix of a spanning tree.\n\n\n\n\n\n","category":"method"},{"location":"IO/#IO-1","page":"IO","title":"IO","text":"","category":"section"},{"location":"IO/#","page":"IO","title":"IO","text":"Modules = [Laplacians]\nPages   = [ \"IO.jl\"]\nPrivate = false","category":"page"},{"location":"IO/#Laplacians.read_graph-Tuple{AbstractString}","page":"IO","title":"Laplacians.read_graph","text":"adj = read_graph(fn)\n\nRead a graph from a file in IJ or IJV format. That is, each line of the file should represent one edge. Each edge should be specified by the indices of its vertices, separated by a whitespace or a comma.  If the graph is weighted, the weight should follow the second index.  For example, the unweighted complete graph on 3 vertices would appear as the file\n\n1 2\n1 3\n2 3\n\nA weighted path on 3 vertices with edge weights 1.5 and 2.5 would be\n\n1, 2, 1.5\n2, 3, 2.5\n\nThe function tries to detect the delimiter type (comma or whitespace) from the first line of the file.  The format must be consistent. Vertex indices start at 1.\n\n\n\n\n\n","category":"method"},{"location":"IO/#Laplacians.writeIJV-Tuple{AbstractString, Any}","page":"IO","title":"Laplacians.writeIJV","text":"Writes the upper portion of a matrix in ijv format, one row for each edge, separated by commas.  Only writes the upper triangular portion. The result can be read from Matlab like this:\n\n>> dl = dlmread('graph.txt');\n>> a = sparse(dl(:,1),dl(:,2),dl(:,3));\n>> n = max(size(a))\n>> a(n,n) = 0;\n>> a = a + a';\n\n\n\n\n\n","category":"method"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"[TOC]","category":"page"},{"location":"usingSolvers/#Solving-linear-equations-in-Laplacians-and-SDD-matrices-1","page":"Solving Linear Equations","title":"Solving linear equations in Laplacians and SDD matrices","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"The main purpose of this package is to experiment with the implementation of algorithms for solving systems of linear equations in Laplacian and symmetric, diagonally dominant, M-matrices (SDDM).","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"At present, the fastest solver in this package for Laplacians is approxchol_lap. A second version approxchol_lap2 is slower but more robust. For SDDM systems, one should use approxchol_sddm.  Here is a quick demo.  Read more for other solvers and other options you can pass to the solvers.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"julia> a = grid3(50); # an adjacency matrix\njulia> la = lap(a); # it's Laplacian\njulia> sol = approxchol_lap(a); # a solver for la\njulia> b = randn(size(la,1)); b = b .- mean(b); # a right-hand-side\njulia> x = sol(b); # the solution\njulia> norm(la*x-b) / norm(b)\n5.911931368666469e-7\njulia> x = sol(b, tol=1e-12); # a higher accuracy solution\njulia> norm(la*x-b) / norm(b)\n7.555529748070115e-11\njulia> x = sol(b, tol=1e-1, verbose=true); # faster, lower accuracy, with info\nPCG stopped after: 0.022 seconds and 3 iterations with relative error 0.07929402690389374.\n\njulia> sddm = copy(la); # doing it with a SDDM matrix\njulia> sddm[1,1] += 1;\njulia> sol = approxchol_sddm(sddm, verbose=true); # solver, with output\nUsing greedy degree ordering. Factorization time: 0.7143130302429199\nRatio of operator edges to original edges: 2.1120548223350255\nratio of max to min diagonal of laplacian : 6.0\nSolver build time: 0.747 seconds.\n\njulia> x = sol(b, verbose=false); # a solve, supressing output\njulia> norm(sddm*x - b) / norm(b)\n8.739618692868002e-7","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"We recall that a matrix $ L $ is a Laplacian matrix if:","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"It is symmetric,\nits off-diagonal entries are non-positive, and\nall of its row sums are 0.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These conditions imply that the diagonal entries are non-negative, and that the matrix is singular.  So, we only hope to solve equations of the form  $ Lx = b $ when b is in the span of the matrix.  When the graph of the nonzero entries of the matrix is connected, this is precisely when the sum of the entries in $ b $ is zero.  Laplacian matrices are always positive semidefinite.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"A matrix $ M $ is a symmetric M-matrix if:","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"It is symmetric,\nits off-diagonal entries are non-positive, and\nit is positive definite.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"A matrix symmetric $ M $ is diagonally dominant if each of its diagonals is at least the sum of the absolute values of the off-diagonal entries in its row.  A Laplacians matrix is diagonally dominant.  A diagonally dominant matrix is always positive semidefinite.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"A SDDM matrix (symmetric, diagonally-dominant M-matrix) is a matrix that is both diagonally dominant and an M-matrix.  You may think of a SDDM matrix as a Laplacian plus a non-negative, non-zero, diagonal matrix.  However, this is only guaranteed to produce a SDDM matrix when the graph underlying the Laplacian is connected.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"Laplacians.jl contains code for solving systems of linear equations in both Laplacian and SDDM matrices.  In fact, these problems are equivalent.  So, usually a solver for one type of system is implemented, and then wrapped to solve the other. The same ideas can be used to solve systems of equations in SDD matrices (the off-diagonals can be positive or negative), but a wrapper for these has not yet been written.","category":"page"},{"location":"usingSolvers/#Harmonic-Interpolation-1","page":"Solving Linear Equations","title":"Harmonic Interpolation","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"One of the main reasons to solve Laplacian and SDDM systems is to interpolate harmonic functions on graphs.  In an unweighted graph, these have the property that the value at every vertex is the average of the values of its neighbors.  To make this sensible, some values must be fixed.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"For example, below we fit a harmonic function on the 4-by-4 grid. We fix the values of vertices 1, 4, and 16 to 0.0, 0.5, and 2.0, respectively.  We then show the results by forcing them into a 4-by-4 grid.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"julia> a = grid2(4);\njulia> S = [1; 4; 16];\njulia> vals = [0; 0.5; 2];\njulia> x = harmonic_interp(a, S, vals);\njulia> reshape(x,4,4)\n4Ã—4 Array{Float64,2}:\n 0.0       0.460942  0.749255  0.903101\n 0.398927  0.633572  0.883721  1.05695\n 0.563208  0.790698  1.09511   1.38402\n 0.5       0.8709    1.322     2.0     ","category":"page"},{"location":"usingSolvers/#The-Solver-Interface-1","page":"Solving Linear Equations","title":"The Solver Interface","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"All of the SDDM solvers take the SDDM matrix as input.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"All of the Laplacian solvers take the adjacency matrix of the underlying graph as input.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"To solve a system of linear equations, one first passes the matrix defining the system to a linear equation solving algorithm.  This will return a function that solves systems of linear equations in that matrix.  For example,","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"julia> n = 1000;\njulia> a = wted_chimera(n);  # produces a graph, as a sparse adjacency matrix\njulia> b = randn(n);\njulia> b = b - mean(b); # so there is a solution\njulia> f = chol_lap(a)\n(::#79) (generic function with 1 method)\njulia> x = f(b);\njulia> la = lap(a);  # construct the Laplacian of a\njulia> norm(la*x-b)\n2.9565023548855584e-13","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"All of the solvers take the following keyword arguments. This means that they are optional, and will be set to their default values if not specified.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"tol : the relative accuracy required: $ \\| M x - b \\| / \\| b \\| $.\nmaxits : the maximum number of iterations, for iterative algorithms.\nmaxtime : quit if it takes more than this many seconds.  Not all routines obey this, but they try.\nverbose : set to true to display diagnostic information.\npcgIts : If the algorithm is iterative, this allows it to return the number of iterations it performed.  If pcgIts is an array of positive length, then its first entry is set to the number of iterations.  Where verbose prints this information, pcgIts allows it to be returned to other code.  To disable this set pcgIts to a zero length array, like Int[].","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"Most of the solvers are iterative, exploiting the preconditioned conjugate gradient. These are the solvers for which maxits, maxtime and pcgIts make the most sense.  Some solvers, like Cholesky factorization, just ignore these parameters.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"All of these parameters may be set in the call that constructs f.  They may then be over-ridden by again setting them in the call to f. Let's see how this works when using the conjugate gradient.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"julia> f = cgLapSolver(a, tol=1e-2, verbose=true)\n(::f) (generic function with 1 method)\njulia> x = f(b);\nCG BLAS stopped after: 78 iterations with relative error 0.009590493139133275.\njulia> norm(la*x-b)/norm(b)\n0.00959049313913375\n\njulia> pcgIts = [0]\n1-element Array{Int64,1}:\n 0\njulia> x = f(b,verbose=false, pcgIts=pcgIts);\njulia> pcgIts\n1-element Array{Int64,1}:\n 78\n\njulia> x = f(b,verbose=true, maxits=50);\nCG BLAS stopped after: 50 iterations with relative error 0.050483096216933886.\n\njulia> x = f(b, tol=1e-4);\nCG BLAS stopped after: 131 iterations with relative error 8.886882933346416e-5.\njulia> norm(la*x-b)/norm(b)\n8.886882933294668e-5","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"For some experiments with solvers, including some of those below, look at the notebook Solvers.ipynb.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"In the following, we document many of the solvers that have been implemented in this package.","category":"page"},{"location":"usingSolvers/#Cholesky-Factorization-1","page":"Solving Linear Equations","title":"Cholesky Factorization","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"Cholesky factorization, the version of Gaussian Elimination for symmetric matrices, should be the first solver you try.  It will be very fast for matrices of dimension less than 1000, and for larger matrices coming from two-dimensional problems.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"You can compute a cholesky factor directly with cholfact.  It does  more than just compute the factor, and it saves its result in a data structure that implements \\.  It uses SuiteSparse by Tim Davis.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"Here is an example of how you would use it to solve a general non-singular linear system.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"a = grid2(5)\nla = lap(a)\nsddm = copy(la)\nsddm[1,1] = sddm[1,1] + 1\nF = cholfact(sddm)\n\nn = size(a)[1]\nb = randn(n)\nx = F \\ b\nnorm(sddm*x-b)\n\n \t1.0598778281116327e-14","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"As cholfact does not satisfy our interface, we wrap it in a routine chol_sddm that does.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"To solve systems in Laplacian matrices, use chol_lap.  Recall that this routine should be passed the adjacency matrix.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"f = chol_lap(a)\nb = randn(n);\nb = b - mean(b);\nnorm(la*f(b) - b)\n\t2.0971536951312585e-15","category":"page"},{"location":"usingSolvers/#CG-and-PCG-1","page":"Solving Linear Equations","title":"CG and PCG","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"We have written implementations of Conjugate Gradient (CG) and Preconditioned Conjugate Gradient (PCG) that satisfy the interface. These routines use BLAS when possible, and slower routines when dealing with data types that BLAS cannot handle.  ","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"seed!(1)\nn = 50\nM = randn(n,n); M = M * M';\nb = randn(n)\nx = cg(M,b,maxits=100,verbose=true);\nCG BLAS stopped after: 66 iterations with relative error 2.0166243927814765e-7.\n\nbbig = convert(Array{BigFloat,1},b)\nxbig = cg(M,bbig,maxits=100,tol=1e-30)\nCG Slow stopped after: 50 iterations with relative error 2.18672511297479336887519117065525148757254642683072581090418060286711737398731e-38.\n\nnorm(M*xbig - bbig)\n1.605742093628722039938504001423963138146137896744531914963345296279741402982296e-37","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"To create a function f that uses cg to solve systems in M, use cgSolver.  For Laplacians, use cgLapSolver.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"julia> n = 1000;\njulia> a = wted_chimera(n,1);\njulia> f = Laplacians.cgLapSolver(a,maxits=100);\n\njulia> b = randn(n);\njulia> b = b - mean(b);\njulia> x = f(b,verbose=true);\nCG BLAS stopped after: 100 iterations with relative error 0.012102058751548373.\n\n\njulia> la = lap(a);\njulia> sddm = copy(la);\njulia> sddm = sddm + spdiagm(rand(n)/100);\njulia> g = cgSolver(sddm,verbose=true)\n(::f) (generic function with 1 method)\n\njulia> x = g(b);\nCG BLAS stopped after: 253 iterations with relative error 7.860172210007891e-7.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"PCG also takes as input a preconditioner.  This should be a function.  Here is an example of how one might construct and use a diagonal preonditioner.  To motivate this, I will use a grid with highly varying weights on edges.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"seed!(1)\na = mapweight(grid2(200),x->1/(rand(1)[1]));\nla = lap(a)\nn = size(la)[1]\nb = randn(n)\nb = b - mean(b);\n\nd = diag(la)\nprec(x) = x ./ d\n@time x = pcg(la,b,prec,maxtime=1,tol=1e-2,verbose=true);\n\nPCG BLAS stopped at maxtime.\nPCG BLAS stopped after: 530 iterations with relative error 0.07732478003311881.\n  1.007756 seconds (10.32 k allocations: 648.525 MB, 9.69% gc time)\n\n@time x = pcg(la,b,prec,maxtime=3,tol=1e-2,verbose=true);\nPCG BLAS stopped after: 1019 iterations with relative error 0.009984013184429813.\n  2.086828 seconds (19.57 k allocations: 1.216 GB, 9.92% gc time)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"Without the preconditioner, CG takes much longer on this example.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"@time x = cg(la,b,tol=1e-2,maxtime=10,verbose=true);\n\nCG BLAS stopped at maxtime.\nCG BLAS stopped after: 8879 iterations with relative error 0.054355534834831624.\n 10.001998 seconds (97.91 k allocations: 2.649 GB, 4.48% gc time)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"pcgSolver creates a function that uses the preconditioner to solve systems in the matrix.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"f = pcgSolver(la,prec)\n@time x = f(b,maxtime=3,tol=1e-2,verbose=true);\nPCG BLAS stopped after: 1019 iterations with relative error 0.009984013184429813.\n  1.892217 seconds (19.58 k allocations: 1.216 GB, 9.47% gc time)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"pcgLapSolver uses the Laplacian of one matrix as a preconditioner for the first.  It solves systems of linear equations in the preconditioner by Cholesky factorization.  It performs the Cholesky factorization when pcgLapSolver is called.  This is why we do the work of creating f only once.  Here is an example using a Low-Stretch Spanning Tree preconditioner.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"@time t = akpw(a)\n  0.210467 seconds (1.43 M allocations: 91.226 MB, 19.23% gc time)\n\n@time f = pcgLapSolver(a,t)\n  0.160210 seconds (288 allocations: 28.076 MB, 72.28% gc time)\n\n@time x = f(b,maxtime=3,tol=1e-2,verbose=true);\nPCG BLAS stopped after: 260 iterations with relative error 0.009864463201800925.\n  1.014897 seconds (28.02 k allocations: 1.008 GB, 9.81% gc time)","category":"page"},{"location":"usingSolvers/#Low-Stretch-Spanning-Trees-1","page":"Solving Linear Equations","title":"Low-Stretch Spanning Trees","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"In order to make preconditioners, we will want low-stretch spanning trees.  We do not yet have any code that is guaranteed to produce these.  Instead, we supply three heuristics: akpw which is inspired by the algorith of Alon, Karp, Peleg and West, and  randomized versions of Prim and Kruskal's algorithm. randishKruskal samples the remaining edges with probability proportional to their weight.  randishPrim samples edges on the boundary while using the same rule.  We recommend using akpw.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"See Low Stretch Spanning Trees to learn more about these.","category":"page"},{"location":"usingSolvers/#Augmented-Spanning-Tree-Preconditioners-1","page":"Solving Linear Equations","title":"Augmented Spanning Tree Preconditioners","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These are obtained by constructing a spanning tree of a graph, and then adding back some more edges from the graph.  The tree should have low stretch.  The edges to add back are chosen at random with probabilities proportional to their stretches.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These are implemented in the routines","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"augTreeSddm, for SDDM matrices\naugTreeLap\naugTreePrecon\naugmentTree","category":"page"},{"location":"usingSolvers/#The-solvers-of-Koutis,-Miller-and-Peng.-1","page":"Solving Linear Equations","title":"The solvers of Koutis, Miller and Peng.","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"Solvers inspired by the algorithm from \"Approaching optimality for solving SDD systems\" by Koutis, Miller, and Peng, <i>SIAM Journal on Computing</i>, 2014.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"KMPLapSolver\nKMPSDDMSolver","category":"page"},{"location":"usingSolvers/#Sampling-Solvers-of-Kyng-and-Sachdeva-1","page":"Solving Linear Equations","title":"Sampling Solvers of Kyng and Sachdeva","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These are inspired by the paper \"Approximate Gaussian Elimination for Laplacians: Fast, Sparse, and Simple\" by Rasmus Kyng and Sushant Sachdeva, FOCS 2016.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These first two follow that paper reasonably closely.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"samplingSDDMSolver\nsamplingLapSolver","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"The following is a modification of the algorithm that eliminates edges one at a time. This solver is by Yuan Gao, Rasmus Kyng, and Daniel A. Spielman.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"The algorithm has not yet been analyzed.  It is presently the fastest in this package, and our recommended choice.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"approxchol_lap","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"A second version is roughly a factor 2 slower, but more robust:","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"approxchol_lap2","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"A detailed description of approxchol_lap and approxchol_lap2 and experimental evaluation of them can be found in the paper \"Robust and Practical Solution of Laplacian Equations by Approximate Elimination\" by Yuan Gao, Rasmus Kyng, and Daniel A. Spielman. Paper link: https://arxiv.org/abs/2303.00709.","category":"page"},{"location":"usingSolvers/#Algebraic-Multigrid-1","page":"Solving Linear Equations","title":"Algebraic Multigrid","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"This is an interface to the algebraic multigrid solvers from the PyAMG package.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"AMGLapSolver\nAMGSolver, for SDDM systems.","category":"page"},{"location":"usingSolvers/#Solvers-from-Matlab-1","page":"Solving Linear Equations","title":"Solvers from Matlab","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"The MATLAB.jl package allows Julia to call routines from Matlab, provided you have Matlab installed.  It does this in a very efficient fashion: it starts up the Matlab process when you type using MATLAB, and then communicates with it.  So, we have wrapped some solvers from Matlab so that they obey the same interface.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These are not part of the Laplacians module, but are included in the package under src/matlabSolvers.jl.  To include them, type","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"include(string(Pkg.dir(\"Laplacians\") , \"/src/matlabSolvers.jl\"))","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"We provide the docstrings for these here.","category":"page"},{"location":"usingSolvers/#Incomplete-Cholesky-Factorizations-1","page":"Solving Linear Equations","title":"Incomplete Cholesky Factorizations","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"These use the no-fill incomplete Cholesky factorizations implemented in Matlab.  They first order the vertices by the symrcm ordering.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"The solvers are:","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"f = matlab_ichol_sddm(sddm; tol, maxtime, maxits, pctIts, verbose)\nf = matlab_ichol_lap(A; tol, maxtime, maxits, pctIts, verbose)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"A routine that just wraps the function that solves equations in the preconditioner is provided as well:","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"f = matlab_ichol(sddm)","category":"page"},{"location":"usingSolvers/#Koutis's-Combinatorial-Multigrid-(CMG)-1","page":"Solving Linear Equations","title":"Koutis's Combinatorial Multigrid (CMG)","text":"","category":"section"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"You must have installed Yiannis Koutis's Combinatorial Multigrid Code, and it must be on Matlab's default path.  As this code returns a function rather than a preconditioner, it would be inefficient to make it use our PCG code and satisfy our interface.  So, it does not.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"x = matlabCmgSolver(mat, b; tol::Real=1e-6, maxits=10000)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"The matrix mat can either be SDDM or a Laplacian.  This solves the system in b.","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"If you need to specify the solver separately from b, you can call","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"x = matlabCmgSolver(mat; tol::Real=1e-6, maxits=10000)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"or, for the Laplacians of the adjacency matrix A,","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"x = matlabCmgLap(A; tol::Real=1e-6, maxits=10000)","category":"page"},{"location":"usingSolvers/#","page":"Solving Linear Equations","title":"Solving Linear Equations","text":"However, this does not create the solver.  It merely returns a call to the previous routine.","category":"page"},{"location":"graphGenerators/#Generators-1","page":"generators","title":"Generators","text":"","category":"section"},{"location":"graphGenerators/#","page":"generators","title":"generators","text":"Laplacians.jl implements generators for many standard graphs. The chimera and wted_chimera generators are designed to stress code by combining these standard graphs in tricky ways.  While no one of these graphs need be a hard case for any application, the goal is for these generators to explore the space of graphs in such a way that running on many of them should exercise your code.","category":"page"},{"location":"graphGenerators/#","page":"generators","title":"generators","text":"chimera(n) generates a random chimera graph. chimera(n,k) first sets the seed of the psrg to k. In this way, it generates the kth chimera graph, and messes with your psrg. wted_chimera is similar, but it generates weighted graphs.","category":"page"},{"location":"graphGenerators/#Function-list-1","page":"generators","title":"Function list","text":"","category":"section"},{"location":"graphGenerators/#","page":"generators","title":"generators","text":"Order = [:type, :function]\nPages   = [\"graphGenerators.md\"]","category":"page"},{"location":"graphGenerators/#","page":"generators","title":"generators","text":"Modules = [Laplacians]\nPages   = [\"graphGenerators.jl\"]\nPrivate = false","category":"page"},{"location":"graphGenerators/#Laplacians.ErdosRenyi-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.ErdosRenyi","text":"graph = ErdosRenyi(n::Integer, m::Integer; ver=Vcur)\n\nGenerate a random graph on n vertices with m edges. The actual number of edges will probably be smaller, as we sample with replacement\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.ErdosRenyiCluster-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.ErdosRenyiCluster","text":"graph = ErdosRenyiCluster(n::Integer, k::Integer; ver=Vcur)\n\nGenerate an ER graph with average degree k, and then return the largest component. Will probably have fewer than n vertices. If you want to add a tree to bring it back to n, try ErdosRenyiClusterFix.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.ErdosRenyiClusterFix-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.ErdosRenyiClusterFix","text":"graph = ErdosRenyiClusterFix(n::Integer, k::Integer; ver=Vcur)\n\nLike an Erdos-Renyi cluster, but add back a tree so it has n vertices\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.bndry_chimera-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.bndry_chimera","text":"Wrapper for boundary chimera.  It returns an SDDM matrix.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.chimera-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.chimera","text":"graph = chimera(n::Integer, k::Integer; verbose=false, ver=Vcur)\n\nBuilds the kth chimeric graph on n vertices. It does this by resetting the random number generator seed. It should captute the state of the generator before that and then return it, but it does not yet.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.chimera-Tuple{Integer}","page":"generators","title":"Laplacians.chimera","text":"graph = chimera(n::Integer; verbose=false, ver=Vcur)\n\nBuilds a chimeric graph on n vertices. The components come from pureRandomGraph, connected by joinGraphs, productGraph and generalizedNecklace\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.complete_binary_tree-Tuple{Integer}","page":"generators","title":"Laplacians.complete_binary_tree","text":"graph = completeBinaryTree(n::Int64)\n\nThe complete binary tree on n vertices\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.complete_bipartite_graph-Tuple{Integer}","page":"generators","title":"Laplacians.complete_bipartite_graph","text":"graph = complete_bipartite_graph(n)\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.complete_graph-Tuple{Integer}","page":"generators","title":"Laplacians.complete_graph","text":"graph = complete_graph(n)\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.empty_graph-Tuple{Integer}","page":"generators","title":"Laplacians.empty_graph","text":"ijv = empty_graph(n)\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.generalized_ring-Union{Tuple{T}, Tuple{T, Array{T}}} where T<:Integer","page":"generators","title":"Laplacians.generalized_ring","text":"graph = generalized_ring(n, gens)\n\nA generalization of a ring graph. The vertices are integers modulo n. Two are connected if their difference is in gens. For example,\n\ngeneralized_ring(17, [1 5])\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.grid2-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.grid2","text":"graph = grid2(n::Int64, m::Int64; isotropy=1)\n\nAn n-by-m grid graph.  iostropy is the weighting on edges in one direction.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.grid2coords-Tuple{Int64, Int64}","page":"generators","title":"Laplacians.grid2coords","text":"graph = grid2coords(n::Int64, m::Int64)\ngraph = grid2coords(n::Int64)\n\nCoordinates for plotting the vertices of the n-by-m grid graph\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.grid3-Tuple{Integer, Integer, Integer}","page":"generators","title":"Laplacians.grid3","text":"graph = grid3(n1, n2, n3)\ngraph = grid3(n)\n\nAn n1-by-n2-by-n3 grid graph.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.grown_graph-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.grown_graph","text":"graph = grown_graph(n, k; ver=Vcur)\n\nCreate a graph on n vertices. For each vertex, give it k edges to randomly chosen prior vertices. This is a variety of a preferential attachment graph.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.grown_graph_d-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.grown_graph_d","text":"graph = grown_graph_d(n::Integer, k::Integer; ver=Vcur)\n\nLike a grownGraph, but it forces the edges to all be distinct. It starts out with a k+1 clique on the first k vertices\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.hypercube-Tuple{Integer}","page":"generators","title":"Laplacians.hypercube","text":"graph = hyperCube(d::Int64)\n\nThe d dimensional hypercube.  Has 2^d vertices and d*2^(d-1) edges.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.path_graph-Tuple{Any}","page":"generators","title":"Laplacians.path_graph","text":"graph = path_graph(n)\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.pref_attach-Tuple{Integer, Integer, Float64}","page":"generators","title":"Laplacians.pref_attach","text":"graph = pref_attach(n::Int64, k::Int64, p::Float64; ver=Vcur)\n\nA preferential attachment graph in which each vertex has k edges to those that come before.  These are chosen with probability p to be from a random vertex, and with probability 1-p to come from the endpoint of a random edge. It begins with a k-clique on the first k+1 vertices.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.pure_random_graph-Tuple{Integer}","page":"generators","title":"Laplacians.pure_random_graph","text":"graph = pure_random_graph(n::Integer; verbose=false, ver=Vcur)\n\nGenerate a random graph with n vertices from one of our natural distributions\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.rand_gen_ring-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.rand_gen_ring","text":"graph = rand_gen_ring(n, k; verbose = false, ver=Vcur)\n\nA random generalized ring graph of degree k. Gens always contains 1, and the other k-1 edge types are chosen from an exponential distribution\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.rand_matching-Tuple{Integer}","page":"generators","title":"Laplacians.rand_matching","text":"graph = rand_matching(n::Integer; ver=Vcur)\n\nA random matching on n vertices\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.rand_regular-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.rand_regular","text":"graph = rand_regular(n, k; ver=Vcur)\n\nA sum of k random matchings on n vertices\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.rand_weight-Tuple{Any}","page":"generators","title":"Laplacians.rand_weight","text":"graph = randWeight(graph; ver=Vcur)\n\nApplies one of a number of random weighting schemes to the edges of the graph\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.ring_graph-Tuple{Any}","page":"generators","title":"Laplacians.ring_graph","text":"graph = ring_graph(n)\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.semiwted_chimera-Tuple{Integer}","page":"generators","title":"Laplacians.semiwted_chimera","text":"graph = semiwted_chimera(n::Integer; verbose=false, ver=Vcur)\n\nA Chimera graph with some weights.  The weights just appear when graphs are combined. For more interesting weights, use wted_chimera\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.star_graph-Tuple{Any}","page":"generators","title":"Laplacians.star_graph","text":"graph = star_graph(n)\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.uni_bndry_chimera-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.uni_bndry_chimera","text":"Wrapper for unweighted boundary chimera. It returns an SDDM matrix.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.uni_chimera-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.uni_chimera","text":"Wrapper for unweighted chimera.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.wted_chimera-Tuple{Integer, Integer}","page":"generators","title":"Laplacians.wted_chimera","text":"graph = wted_chimera(n::Integer, k::Integer; verbose=false, ver=Vcur)\n\nBuilds the kth wted chimeric graph on n vertices. It does this by resetting the random number generator seed. It should captute the state of the generator before that and then return it, but it does not yet.\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Laplacians.wted_chimera-Tuple{Integer}","page":"generators","title":"Laplacians.wted_chimera","text":"graph = wted_chimera(n::Integer)\n\nGenerate a chimera, and then apply a random weighting scheme\n\n\n\n\n\n","category":"method"},{"location":"graphGenerators/#Random.randperm-Tuple{AbstractMatrix}","page":"generators","title":"Random.randperm","text":"graph = randperm(mat::AbstractMatrix)\n        randperm(f::Expr)\n\nRandomly permutes the vertex indices\n\n\n\n\n\n","category":"method"},{"location":"akpw/#AKPW-1","page":"akpw","title":"AKPW","text":"","category":"section"},{"location":"akpw/#","page":"akpw","title":"akpw","text":"Also see the page on Low Stretch Spanning Trees","category":"page"},{"location":"akpw/#","page":"akpw","title":"akpw","text":"Order = [:type, :function]\nPages   = [\"akpw.md\"]","category":"page"},{"location":"akpw/#","page":"akpw","title":"akpw","text":"Modules = [Laplacians]\nPages   = [\"akpw.jl\"]\nPrivate = false","category":"page"},{"location":"akpw/#Laplacians.akpw-Tuple{Any}","page":"akpw","title":"Laplacians.akpw","text":"tree = akpw(graph; ver=0)\n\nComputes a low stretch spanning tree of graph, and returns it as a graph. The default version is 0.  In event of emergency, one can try ver=2.  It is usually slower, but might have slightly better stretch.\n\n\n\n\n\n","category":"method"},{"location":"akpw/#Laplacians.akpwU-Tuple{Any}","page":"akpw","title":"Laplacians.akpwU","text":"tree = akpwU(graph)\n\nComputes a low stretch spanning tree of an unweighted graph, and returns it as a graph.\n\n\n\n\n\n","category":"method"},{"location":"LSST/#Low-Stretch-Spanning-Trees-1","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"","category":"section"},{"location":"LSST/#","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"We have implemented a variant of the algorithm of Alon, Karp, Peleg and West for computing low stretch spanning trees.  It is called akpw.  For unweighted graphs we provide a faster variant called akpwU.  If you require faster algorithms, with possibly higher average stretch, you can try the heuristics randishPrim or randishKruskal.","category":"page"},{"location":"LSST/#","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"You can compute the stretch of a graph with respect to a spanning tree with the routine comp_stretches.  It returns a sparse matrix with one entry for each edge in the graph giving its stretch.  For example:","category":"page"},{"location":"LSST/#","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"julia> graph = grid2(4)\n16x16 sparse matrix with 48 Float64 entries:\n\njulia> tree = akpwU(graph)\n16x16 sparse matrix with 30 Float64 entries:\n\njulia> st = comp_stretches(tree,graph)\n16x16 sparse matrix with 48 Float64 entries:\n\t[2 ,  1]  =  1.0\n\t[5 ,  1]  =  1.0\n\t[1 ,  2]  =  1.0\n\t[3 ,  2]  =  1.0\n\t[6 ,  2]  =  3.0\n\t[2 ,  3]  =  1.0\n\t[4 ,  3]  =  1.0\n\t[7 ,  3]  =  1.0\n\t[3 ,  4]  =  1.0\n\t[8 ,  4]  =  3.0\n\t[1 ,  5]  =  1.0\n\t[6 ,  5]  =  5.0\n\tâ‹®\n\t[8 , 12]  =  3.0\n\t[11, 12]  =  1.0\n\t[16, 12]  =  1.0\n\t[9 , 13]  =  1.0\n\t[14, 13]  =  3.0\n\t[10, 14]  =  1.0\n\t[13, 14]  =  3.0\n\t[15, 14]  =  3.0\n\t[11, 15]  =  1.0\n\t[14, 15]  =  3.0\n\t[16, 15]  =  3.0\n\t[12, 16]  =  1.0\n\t[15, 16]  =  3.0","category":"page"},{"location":"LSST/#","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"Here is an example demonstrating the average stretches and times taken by these algorithms on a large graph.","category":"page"},{"location":"LSST/#","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"\njulia> graph = chimera(1000000,1);\n\njulia> @time tree = akpw(graph);\n  5.700285 seconds (16.10 M allocations: 1.263 GB, 11.16% gc time)\n\njulia> aveStretch = sum(comp_stretches(tree,graph))/nnz(graph)\n8.793236275779616\n\njulia> @time tree = randishPrim(graph);\n  3.736225 seconds (3.21 M allocations: 566.887 MB, 6.40% gc time)\n\njulia> aveStretch = sum(comp_stretches(tree,graph))/nnz(graph)\n10.800094649795756\n\njulia> @time tree = randishKruskal(graph);\n  2.515443 seconds (3.21 M allocations: 423.529 MB, 4.35% gc time)\n\njulia> aveStretch = sum(comp_stretches(tree,graph))/nnz(graph)\n37.819948689847564\n","category":"page"},{"location":"LSST/#","page":"Low Stretch Spanning Trees","title":"Low Stretch Spanning Trees","text":"Of course, you can get very different results on very different graphs.  But, the ordering of these algorithms respect to time and stretch will usually follow this pattern.","category":"page"},{"location":"solvers/#Linear-Equation-Solvers-1","page":"solvers","title":"Linear Equation Solvers","text":"","category":"section"},{"location":"solvers/#","page":"solvers","title":"solvers","text":"For more, see the page on using solvers.","category":"page"},{"location":"solvers/#","page":"solvers","title":"solvers","text":"Order = [:type, :function]\nPages   = [\"solvers.md\"]","category":"page"},{"location":"solvers/#","page":"solvers","title":"solvers","text":"Modules = [Laplacians]\nPages   = [\"solverInterface.jl\", \"pcg.jl\",\"approxChol.jl\", \"augTreeSolver.jl\", \"samplingSolver.jl\",\"KMPSolver.jl\", \"externalSolvers.jl\", \"harmonic.jl\"]\nPrivate = false","category":"page"},{"location":"solvers/#Laplacians.chol_lap","page":"solvers","title":"Laplacians.chol_lap","text":"solver = chol_lap(A::AbstractArray)\n\nUses Cholesky Factorization to solve systems in Laplacians.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.chol_sddm","page":"solvers","title":"Laplacians.chol_sddm","text":"solveSDDM = chol_sddm(sddm::AbstractMatrix; tol, maxits, maxtime, verbose, pcgIts=Int[])\n\nThis functions wraps cholfact so that it satsfies our interface. It ignores all the keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.lapWrapSDDM-Tuple{Any, AbstractArray}","page":"solvers","title":"Laplacians.lapWrapSDDM","text":"f = lapWrapSDDM(sddmSolver, A::AbstractArray; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[], params...)\nf = lapWrapSDDM(sddmSolver)\n\nUses a sddmSolver to solve systems of linear equations in Laplacian matrices.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.cg","page":"solvers","title":"Laplacians.cg","text":"x = cg(mat, b; tol, maxits, maxtime, verbose, pcgIts)\n\nsolves a symmetric linear system mat x = b.\n\nArguments\n\ntol is set to 1e-6 by default,\nmaxits defaults to Inf\nmaxtime defaults to Inf.  It measures seconds.\nverbose defaults to false\npcgIts is an array for returning the number of pcgIterations.  Default is length 0, in which case nothing is returned.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.cgLapSolver-Tuple{SparseArrays.SparseMatrixCSC}","page":"solvers","title":"Laplacians.cgLapSolver","text":"x = cgLapSolver(A::AbstractMatrix; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[])\n\nCreate a solver that uses cg to solve Laplacian systems in the laplacian of A. This just exists to satisfy our interface. It does nothing more than create the Laplacian and call cg on each connected component.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.cgSolver","page":"solvers","title":"Laplacians.cgSolver","text":"x = cgSolver(mat; tol, maxits, maxtime, verbose, pcgIts)\n\ncreates a solver for a PSD system mat. The parameters are as described in cg.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.pcg","page":"solvers","title":"Laplacians.pcg","text":"x = pcg(mat, b, pre; tol, maxits, maxtime, verbose, pcgIts, stag_test)`\n\nsolves a symmetric linear system using preconditioner pre.\n\nArguments\n\npre can be a function or a matrix.  If a matrix, a function to solve it is created with cholFact.\ntol is set to 1e-6 by default,\nmaxits defaults to Inf\nmaxtime defaults to Inf.  It measures seconds.\nverbose defaults to false\npcgIts is an array for returning the number of pcgIterations.  Default is length 0, in which case nothing is returned.\nstag_test=k stops the code if rho[it] > (1-1/k) rho[it-k].  Set to 0 to deactivate.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.pcgLapSolver-Tuple{AbstractMatrix, AbstractMatrix}","page":"solvers","title":"Laplacians.pcgLapSolver","text":"x = pcgLapSolver(A, B; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[])\n\nCreate a solver that uses pcg to solve Laplacian systems in A Specialized for the case when the preconditioner the Laplacian matrix of B. It solves the preconditioner by Cholesky Factorization.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.pcgSolver","page":"solvers","title":"Laplacians.pcgSolver","text":"x = pcgSolver(mat, pre; tol, maxits, maxtime, verbose, pcgIts)\n\ncreates a solver for a PSD system using preconditioner pre. The parameters are as described in pcg.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.approxchol_lap-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"solvers","title":"Laplacians.approxchol_lap","text":"solver = approxchol_lap(a); x = solver(b);\nsolver = approxchol_lap(a; tol::Real=1e-6, maxits=1000, maxtime=Inf, verbose=false, pcgIts=Int[], params=ApproxCholParams())\n\nA heuristic solver by Yuan Gao, Rasmus Kyng, and Daniel Spielman, see paper https://arxiv.org/abs/2303.00709. The solver is inspired by the solver in https://arxiv.org/abs/1605.02353 by Rasmus Kyng and Sushant Sachdeva. Whereas that paper eliminates vertices one at a time, this eliminates edges one at a time.  It is probably possible to analyze it. The ApproxCholParams let you choose one of three orderings to perform the elimination.\n\nApproxCholParams(:given) - in the order given.   This is the fastest for construction the preconditioner, but the slowest solve.\nApproxCholParams(:deg) - always eliminate the node of lowest degree.   This is the slowest build, but the fastest solve.\nApproxCholParams(:wdeg) - go by a perturbed order of wted degree.\n\nFor more info, see http://danspielman.github.io/Laplacians.jl/dev/usingSolvers/index.html\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.approxchol_lap2-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"solvers","title":"Laplacians.approxchol_lap2","text":"solver = approxchol_lap2(a); x = solver(b);\nsolver = approxchol_lap2(a; tol::Real=1e-6, maxits=1000, maxtime=Inf, verbose=false, pcgIts=Int[], params=ApproxCholParams())\n\napproxchol_lap2 is slower than approxchol_lap (by roughly a factor 2), but is more robust.\n\nA heuristic solver by Yuan Gao, Rasmus Kyng, and Daniel Spielman, see paper https://arxiv.org/abs/2303.00709. The solver is inspired by the solver in https://arxiv.org/abs/1605.02353 by Rasmus Kyng and Sushant Sachdeva. Whereas that paper eliminates vertices one at a time, this eliminates edges one at a time.  It is probably possible to analyze it.\n\napproxchol_lap2 only implements the ordering given by ApproxCholParams(:deg) - always eliminate the node of lowest degree.\n\nFor more info, see http://danspielman.github.io/Laplacians.jl/dev/usingSolvers/index.html\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.approxchol_sddm","page":"solvers","title":"Laplacians.approxchol_sddm","text":"solver = approxchol_sddm(sddm); x = solver(b);\nsolver = approxchol_sddm(sddm; tol=1e-6, maxits=1000, maxtime=Inf, verbose=false, pcgIts=Int[], params=ApproxCholParams())\n\nSolves sddm systems by wrapping approxchol_lap. Not yet optimized directly for sddm.\n\nFor more info, see http://danspielman.github.io/Laplacians.jl/latest/usingSolvers/index.html\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Laplacians.condNumber-Tuple{Any, Any}","page":"solvers","title":"Laplacians.condNumber","text":"cn = condNumber(a, ldli; verbose=false)\n\nGiven an adjacency matrix a and an ldli computed by approxChol, this computes the condition number.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.augTreeLap-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"solvers","title":"Laplacians.augTreeLap","text":"solver = augTreeLap(A; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[], params=AugTreeParams())\n\nAn \"augmented spanning tree\" solver for Laplacians.  It works by adding edges to a low stretch spanning tree.  It calls augTreePrecon to form the preconditioner.  params has entries\n\nparams.treeAlg default to akpw\nparams.opt if true, it interacts with cholmod to choose a good number of edges to add back.  If false, it adds back 2*sqrt(n).\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.augTreeLapPrecon-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"solvers","title":"Laplacians.augTreeLapPrecon","text":"pre = augTreeLapPrecon{Tv,Ti}(A; params=AugTreeParams())\n\nThis is an augmented spanning tree preconditioner for Laplacians. It takes as optional input a tree growing algorithm. It adds back 2sqrt(n) edges via augmentTree: the sqrt(n) of highest stretch and another sqrt(n) sampled according to stretch. For most purposes, one should directly call augTreeLapSolver.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.augTreePrecon-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"solvers","title":"Laplacians.augTreePrecon","text":"pre = augTreePrecon{Tv,Ti}(ddmat::SparseMatrixCSC{Tv,Ti}; params=AugTreeParams())\n\nThis is an augmented spanning tree preconditioner for diagonally dominant linear systems.  It takes as optional input a tree growing algorithm. It adds back 2sqrt(n) edges via augmentTree: the sqrt(n) of highest stretch and another sqrt(n) sampled according to stretch. For most purposes, one should directly call augTreeSolver.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.augTreeSddm-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"solvers","title":"Laplacians.augTreeSddm","text":"solver = augTreeSddm(sddm; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[],  params=AugTreeParams())\n\nAn \"augmented spanning tree\" solver for positive definite diagonally dominant matrices.  It works by adding edges to a low stretch spanning tree.  It calls augTreePrecon to form the preconditioner.  params has entries\n\nparams.treeAlg default to akpw\nparams.opt if true, it interacts with cholmod to choose a good number of edges to add back.  If false, it adds back 2*sqrt(n).\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.augmentTree-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, SparseArrays.SparseMatrixCSC{Tv, Ti}, Ti}} where {Tv, Ti}","page":"solvers","title":"Laplacians.augmentTree","text":"B = augmentTree{Tv,Ti}(tree, A, k)\n\nTakes as input a tree and an adjacency matrix of a graph. It then computes the stretch of every edge of the graph wrt the tree.  It then adds back the k edges of highest stretch, and k edges sampled according to stretch.\n\nThis is the old alg.  We now recommend using augmentTreeOpt.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.KMPParams","page":"solvers","title":"Laplacians.KMPParams","text":"Parameters for the KMP solver\n\n\n\n\n\n","category":"type"},{"location":"solvers/#Laplacians.KMPLapSolver-Tuple{Any}","page":"solvers","title":"Laplacians.KMPLapSolver","text":"lapSolver = KMPLapSolver(A; verbose, tol, maxits, maxtime, pcgIts, params::KMPParams)\n\nSolves linear equations in the Laplacian of graph with adjacency matrix A.\n\nBased on the paper \"Approaching optimality for solving SDD systems\" by Koutis, Miller, and Peng, <i>SIAM Journal on Computing</i>, 2014.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.KMPSDDMSolver-Tuple{Any}","page":"solvers","title":"Laplacians.KMPSDDMSolver","text":"sddmSolver = KMPSDDMSolver(mat; verbose, tol, maxits, maxtime, pcgIts, params::KMPParams)\n\nSolves linear equations in symmetric, diagonally dominant matrices with non-positive off-diagonals.  Based on the paper \"Approaching optimality for solving SDD systems\" by Koutis, Miller, and Peng, <i>SIAM Journal on Computing</i>, 2014.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Laplacians.harmonic_interp-Tuple{Any, Vector, Vector}","page":"solvers","title":"Laplacians.harmonic_interp","text":"x = harmonic_interp(adj_mat, S, vals; tol=1e-6)\n\nInterpolates a function on a graph, given by its adjacency matrix, by minizing the Laplacian quadratic form subject to the boundary conditions that x[S[i]] = vals[i] for i in S.\n\nThis is the algorithm sometimes known as Label Propagation, or Semi-Supervised Learning on Graphs.  The idea comes from the paper \"Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions\" by Zhu, Gharamani, and Lafferty from ICML 2003.\n\nThis version might fail for disconnected graphs. You can check if a graph is connected with isConnected(adj_mat).\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Graph-Algorithms-1","page":"graphAlgs","title":"Graph Algorithms","text":"","category":"section"},{"location":"graphAlgs/#","page":"graphAlgs","title":"graphAlgs","text":"These are basic graph algorithms.","category":"page"},{"location":"graphAlgs/#Function-list-1","page":"graphAlgs","title":"Function list","text":"","category":"section"},{"location":"graphAlgs/#","page":"graphAlgs","title":"graphAlgs","text":"Order = [:type, :function]\nPages   = [\"graphAlgs.md\"]","category":"page"},{"location":"graphAlgs/#","page":"graphAlgs","title":"graphAlgs","text":"Modules = [Laplacians]\nPages   = [\"graphAlgs.jl\"]\nPrivate = false","category":"page"},{"location":"graphAlgs/#Laplacians.biggestComp-Tuple{SparseArrays.SparseMatrixCSC}","page":"graphAlgs","title":"Laplacians.biggestComp","text":"Return the biggest component in a graph, as a graph\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.components-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"graphAlgs","title":"Laplacians.components","text":"Computes the connected components of a graph. Returns them as a vector of length equal to the number of vertices. The vector numbers the components from 1 through the maximum number. For example,\n\ngr = ErdosRenyi(10,11)\nc = components(gr)\n\n10-element Array{Int64,1}:\n 1\n 1\n 1\n 1\n 2\n 1\n 1\n 1\n 3\n 2\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.isConnected-Tuple{SparseArrays.SparseMatrixCSC}","page":"graphAlgs","title":"Laplacians.isConnected","text":"Returns true if graph is connected.  Calls components.\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.kruskal-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"graphAlgs","title":"Laplacians.kruskal","text":"(kruskal::SparseMatrixCSC; kind=:max) Uses Kruskal's algorithm to compute a minimum (or maximum) spanning tree. Set kind=:min if you want the min spanning tree. It returns it a a graph\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.prim-Tuple{SparseArrays.SparseMatrixCSC}","page":"graphAlgs","title":"Laplacians.prim","text":"prim(mat::SparseMatrixCSC; kind=:max) Compute a maximum spanning tree of the matrix mat.   If kind=:min, computes a minimum spanning tree.\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.shortestPathTree-Tuple{Any, Any}","page":"graphAlgs","title":"Laplacians.shortestPathTree","text":"Computes the shortest path tree, and returns it as a sparse matrix. Treats edge weights as reciprocals of lengths. For example:\n\na = [0 2 1; 2 0 3; 1 3 0]\ntr = full(shortestPathTree(sparse(a),1))\n\n3x3 Array{Float64,2}:\n 0.0  2.0  0.0\n 2.0  0.0  3.0\n 0.0  3.0  0.0\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.shortestPaths-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Ti}} where {Tv, Ti}","page":"graphAlgs","title":"Laplacians.shortestPaths","text":"Computes the lenghts of shortest paths from start. Returns both a vector of the lenghts, and the parent array in the shortest path tree.\n\nThis algorithm treats edge weights as reciprocals of distances. DOC BETTER\n\n\n\n\n\n","category":"method"},{"location":"graphAlgs/#Laplacians.vecToComps-Union{Tuple{Vector{Ti}}, Tuple{Ti}} where Ti","page":"graphAlgs","title":"Laplacians.vecToComps","text":"This turns a component vector, like that generated by components, into an array of arrays of indices of vertices in each component.  For example,\n\ncomps = vecToComps(c)\n\n3-element Array{Array{Int64,1},1}:\n [1,2,3,4,6,7,8]\n [5,10]\n [9]\n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Graph-Utilities-1","page":"graphUtils","title":"Graph Utilities","text":"","category":"section"},{"location":"graphUtils/#","page":"graphUtils","title":"graphUtils","text":"These are utilities to facilitate the use of sparse matrices as graphs.","category":"page"},{"location":"graphUtils/#","page":"graphUtils","title":"graphUtils","text":"Order = [:type, :function]\nPages   = [\"graphUtils.md\"]","category":"page"},{"location":"graphUtils/#","page":"graphUtils","title":"graphUtils","text":"Modules = [Laplacians]\nPages   = [\"graphUtils.jl\"]\nPrivate = false","category":"page"},{"location":"graphUtils/#Laplacians.backIndices-Union{Tuple{Array{Array{Tuple{Tv1, Tv2}, 1}, 1}}, Tuple{Tv2}, Tuple{Tv1}} where {Tv1, Tv2}","page":"graphUtils","title":"Laplacians.backIndices","text":"Same as the above, but now the graph is in adjacency list form \n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.backIndices-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.backIndices","text":"Computes the back indices in a graph in O(M+N). works if for every edge (u,v), (v,u) is also in the graph \n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.compConductance-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.compConductance","text":"Returns the quality of the cut for a given graph and a given cut set s.   the result will be |outgoing edges| / min(|vertices in set|, |N - vertices in set|)\n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.findEntries-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.findEntries","text":"Similar to findnz, but also returns 0 entries that have an edge in the sparse matrix \n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.flipIndex-Union{Tuple{SparseArrays.SparseMatrixCSC{Tval, Tind}}, Tuple{Tind}, Tuple{Tval}} where {Tval, Tind}","page":"graphUtils","title":"Laplacians.flipIndex","text":"For a symmetric matrix, this gives the correspondance between pairs of entries in an ijv. So, ai[ind] = aj[flip[ind]].  For example, \n\n(ai,aj,av) = findnz(a);\nfl = flipIndex(a)\nind = 10\n@show backind = fl[10]\n@show [ai[ind], aj[ind], av[ind]]\n@show [ai[backind], aj[backind], av[backind]];\n\nbackind = fl[10] = 4\n[ai[ind],aj[ind],av[ind]] = [2.0,4.0,0.7]\n[ai[backind],aj[backind],av[backind]] = [4.0,2.0,0.7]\n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.getObound-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.getObound","text":"Computes the number of edges leaving s \n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.getVolume-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.getVolume","text":"Computes the volume of subset s in an unweighted graph G \n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.setValue-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Ti, Ti, Tv}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.setValue","text":"Sets the value of a certain edge in a sparse graph; value can be 0 without the edges dissapearing \n\n\n\n\n\n","category":"method"},{"location":"graphUtils/#Laplacians.wdeg-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Ti}} where {Tv, Ti}","page":"graphUtils","title":"Laplacians.wdeg","text":"Finds the weighted degree of a vertex in the graph \n\n\n\n\n\n","category":"method"},{"location":"Developing/#Developing-Laplacians.jl-1","page":"Developing","title":"Developing Laplacians.jl","text":"","category":"section"},{"location":"Developing/#Learn-to-use-git-1","page":"Developing","title":"Learn to use git","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"If you don't know anything about git, then just know that you should make a branch for you own code.  Type","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"git checkout -b MyName","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Make sure that your .gitignore file contains the lines","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"*~\n*#\n.ipynb_*\n.DS_Store\n*.cov\ndocs/build\ndocs/site","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Now, read about Git.  I recommend the book Pro Git, which is available online for free.\nStop thinking about Git like subversion or dropbox.\nThe master branch will be the one for public consumption. It should (mostly) work.\nYou should also read the ","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"section of the Julia docs about building packages.","category":"page"},{"location":"Developing/#Tests-1","page":"Developing","title":"Tests","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Every piece of code should have a test in the \"tests\" directory.  Ideally, it should have enough tests to run every line of the code.  To run all the tests from the command prompt, type","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"julia -e 'Pkg.test(\"Laplacians\")'","category":"page"},{"location":"Developing/#Fast-code?-1","page":"Developing","title":"Fast code?","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Just go for it. Don't worry about writing fast code at first. Just get it to work. We can speed it up later.","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Within some of the files, I am keeping old, unoptimized versions of code around for comparison (and for satisfaction).  I will give them the name \"XSlow\"","category":"page"},{"location":"Developing/#Documentation-1","page":"Developing","title":"Documentation","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"This documentation is still very rough. It is generated by a combination of Markdown and semi-automatic generation, using the Documenter.jl package.  The one annoying feature of this package is that it will not allow the inclusion of a docstring on more than one page.  I don't know why.","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"The steps to generate and improve the documentation are:","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Edit Markdown files in the docs directory.  For example, you could use MacDown to do this.\nIf you want to add a new page to the documention, create one.  Edit the file mkdocs.yml so show where it should appear.\nAdd docstrings to everything that needs it, and in particular to the routines you create.  The API is built from the docstrings. \nRun julia make.jl; mkdocs build in the docs directory to generate the documentation from the Markdown.  This will generate a local copy of the documentation that you can use for reference.\nWARNING: You should not include any pages that are generated in the git repository.  So, make sure that your .gitignore file contains the line docs/build and docs/site.","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"When you push to the master branch on GitHub, Travis will automatically build and update the docs.  <b>DO NOT RUN mkdocs gh-deploy</b>","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"If you create a Julia notebook that you would like to include as documentation.   You should  put it in the notebooks directory (.julia/v0.5/Laplacians/notebooks) and then link to it's page on GitHub.  While it seems that one should convert it to html (and one can), and then include it in MkDocs, MkDocs does something funny to the resulting html that does not look nice.","category":"page"},{"location":"Developing/#Parametric-Types-1","page":"Developing","title":"Parametric Types","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"A sparse matrix has two types associated with it: the types of its indices (some sort of integer) and the types of its values (some sort of number).  Most of the code has been written so that once these types are fixed, the type of everything else in the function has been too.  This is accomplished by putting curly braces after a function name, with the names of the types that we want to use in the braces.  For example,","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"shortestPaths{Tv,Ti}(mat::SparseMatrixCSC{Tv,Ti}, start::Ti)","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Tv, sometimes written Tval denotes the types of the values, and Ti or Tind denotes the types of the indices.  This function will only be called if the node from which we compute the shortest paths, start is of type Ti.  Inside the code, whenever we write something like pArray = zeros(Ti,n), it creates an array of zeros of type Ti.  Using these parameteric types is much faster than leaving the types unfixed.","category":"page"},{"location":"Developing/#Data-structures:-1","page":"Developing","title":"Data structures:","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"IntHeap a heap that stores small integers (like indices of nodes in a graph) and that makes deletion fast.  Was much faster than using Julia's more general heap.","category":"page"},{"location":"Developing/#Interface-issue:-1","page":"Developing","title":"Interface issue:","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"There are many different sorts of things that our code could be passing around.  For example, kruskal returns a graph as a sparse matrix.  But, we could use a format that is more specialized for trees, like the RootedTree type.  At some point, when we optimize code, we will need to figure out the right interfaces between routines.  For example, some routines symmetrize at the end.  This is slow, and should be skipped if not necessary.  It also doubles storage.","category":"page"},{"location":"Developing/#Integration-with-other-packages.-1","page":"Developing","title":"Integration with other packages.","text":"","category":"section"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"There are other graph packages that we might want to sometimes use.","category":"page"},{"location":"Developing/#","page":"Developing","title":"Developing","text":"Graphs.jl : I found this one to be too slow and awkward to be useful.\nLightGraphs.jl : this looks more promising.  We will have to check it out.  It is reasonably fast, and the code looks pretty.","category":"page"},{"location":"operators/#Operators-1","page":"operators","title":"Operators","text":"","category":"section"},{"location":"operators/#","page":"operators","title":"operators","text":"Operators transform graphs to produce new graphs.","category":"page"},{"location":"operators/#Function-list-1","page":"operators","title":"Function list","text":"","category":"section"},{"location":"operators/#","page":"operators","title":"operators","text":"Order = [:type, :function]\nPages   = [\"graphOps.md\"]","category":"page"},{"location":"operators/#","page":"operators","title":"operators","text":"Modules = [Laplacians]\nPages   = [\"graphOps.jl\"]\nPrivate = false","category":"page"},{"location":"operators/#Laplacians.adj-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"operators","title":"Laplacians.adj","text":"a,d = adj(sddm)\n\nCreate an adjacency matrix and a diagonal vector from an SDD M-matrix. That is, from a Laplacian with added diagonal weights\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.diagmat-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"operators","title":"Laplacians.diagmat","text":"d = diagmat(a)\n\nReturns the diagonal weighted degree matrix(as a sparse matrix) of a graph\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.disjoin-Tuple{SparseArrays.SparseMatrixCSC, SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.disjoin","text":"graph = disjoin(a,b)\n\nCreate a disjoint union of graphs a and b,   with no edges between them.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.edgeVertexMat-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.edgeVertexMat","text":"U = edgeVertexMat(a)\n\nThe signed edge-vertex adjacency matrix\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.floatGraph-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.floatGraph","text":"graph = floatGraph(a::SparseMatrixCSC)\n\nConvert the nonzero entries in a graph to Float64.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.join_graphs!-Tuple{Laplacians.IJV, Laplacians.IJV, Integer}","page":"operators","title":"Laplacians.join_graphs!","text":"graph = join_graphs!(a::IJV, b::IJV, k::Integer)\n\nCreate a disjoint union of graphs a and b,  and then put k random edges between them, merging b into a.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.join_graphs-Union{Tuple{Tind}, Tuple{Tval}, Tuple{SparseArrays.SparseMatrixCSC{Tval, Tind}, SparseArrays.SparseMatrixCSC{Tval, Tind}, Integer}} where {Tval, Tind}","page":"operators","title":"Laplacians.join_graphs","text":"graph = joinGraphs(a, b, k::Integer)\n\nCreate a disjoint union of graphs a and b,  and then put k random edges between them\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.lap-Tuple{Any}","page":"operators","title":"Laplacians.lap","text":"l = lap(a)\n\nCreate a Laplacian matrix from an adjacency matrix. We might want to do this differently, say by enforcing symmetry\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.line_graph-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.line_graph","text":"H = line_graph(G::SparseMatrixCSC)\n\nLet G = (V, E) be a graph. The line graph of G is the graph whose vertices are the edges of G in which two are connected if they share an endpoint in G. That is, (u, v),(w, z) is an edge of the line graph if one of {u, v} is the same as one of {w, z}\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.mapweight-Union{Tuple{Tind}, Tuple{Tval}, Tuple{SparseArrays.SparseMatrixCSC{Tval, Tind}, Any}} where {Tval, Tind}","page":"operators","title":"Laplacians.mapweight","text":"b = mapweight(a, x->rand())\n\nCreate a new graph that is the same as the original, but with f applied to each nonzero entry of a. For example, to make the weight of every edge uniform in [0,1], we could write.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.plot_graph-NTuple{4, Any}","page":"operators","title":"Laplacians.plot_graph","text":"plot_graph(gr,x,y,z;color=[0,0,1],dots=true,setaxis=true,number=false)\n\nPlots graph gr with coordinates (x,y,z)\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.plot_graph-Tuple{Any, Any, Any}","page":"operators","title":"Laplacians.plot_graph","text":"plot_graph(gr,x,y;color=[0,0,1],dots=true,setaxis=true,number=false)\n\nPlots graph gr with coordinates (x,y)\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.power-Tuple{SparseArrays.SparseMatrixCSC, Int64}","page":"operators","title":"Laplacians.power","text":"ap = power(a::SparseMatrixCSC, k::Int)\n\nReturns the kth power of a.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.product_graph-Tuple{SparseArrays.SparseMatrixCSC, SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.product_graph","text":"aprod = productGraph(a0, a1)\n\nThe Cartesian product of two graphs.  When applied to two paths, it gives a grid.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.shortIntGraph-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.shortIntGraph","text":"graph = shortIntGraph(a::SparseMatrixCSC)\n\nConvert the indices in a graph to 32-bit ints. This takes less storage, but does not speed up much.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.spectral_coords-Tuple{Any}","page":"operators","title":"Laplacians.spectral_coords","text":"x, y = spectral_coords(a)\n\nComputes the spectral coordinates of a graph. If more than 2 coords are desired, you can use\n\n    x, y, z = spectral_coords(a; k = 3)\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.spectral_drawing-Tuple{Any}","page":"operators","title":"Laplacians.spectral_drawing","text":"spectral_drawing(a)\n\nComputes spectral coordinates, and then uses plot_graph to draw\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.subsampleEdges-Tuple{SparseArrays.SparseMatrixCSC, Float64}","page":"operators","title":"Laplacians.subsampleEdges","text":"graph = subsampleEdges(a::SparseMatrixCSC, p::Float64)\n\nCreate a new graph from the old, but keeping edge edge with probability p\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.thicken-Tuple{SparseArrays.SparseMatrixCSC, Any}","page":"operators","title":"Laplacians.thicken","text":"a_new = thicken(A,k)\n\nCreate a new graph with at least k times as many edges as A By connecting nodes with common neighbors at random. When this stops working (not enough new edges), repeat on the most recently produced graph. If k is too big, it is decreased so the average degree will not be pushed much above n/2.\n\nWhen called without k, it just runs thicken_once.\n\nFor example:\n\na = grid2(5)\na2 = thicken(a,3)\n(x,y) = grid2coords(5,5);\nplotGraph(a2,x,y)\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.thicken_once-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.thicken_once","text":"a_new = thicken_once(a)\n\nCreates one edge for every vertex in a of degree > 1 by connecting two of its random neighbors. To use this to thicken a, return unweight(a + a_new).\n\na = grid2(5)\na2 = unweight(a + thicken_once(a))\n(x,y) = grid2coords(5,5);\nplotGraph(a2,x,y)\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.two_lift-Tuple{SparseArrays.SparseMatrixCSC, AbstractVector{Bool}}","page":"operators","title":"Laplacians.two_lift","text":"graph = two_lift(a, flip::AbstractArray{Bool,1})\ngraph = two_lift(a)\ngraph = two_lift(a, k::Integer)\n\nCreats a 2-lift of a.  flip is a boolean indicating which edges cross. In the third version, k is the number of edges that cross.\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.uniformWeight!-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.uniformWeight!","text":"uniformWeight!(a)\n\nSet the weight of every edge to random uniform [0,1]\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.unweight!-Union{Tuple{SparseArrays.SparseMatrixCSC{Tval, Tind}}, Tuple{Tind}, Tuple{Tval}} where {Tval, Tind}","page":"operators","title":"Laplacians.unweight!","text":"unweight!(a)\n\nChange the weight of every edge in a to 1\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.unweight-Union{Tuple{SparseArrays.SparseMatrixCSC{Tval, Tind}}, Tuple{Tind}, Tuple{Tval}} where {Tval, Tind}","page":"operators","title":"Laplacians.unweight","text":"wt1 = unweight(a)\n\nCreate a new graph in that is the same as the original, but with all edge weights 1\n\n\n\n\n\n","category":"method"},{"location":"operators/#Laplacians.wtedEdgeVertexMat-Tuple{SparseArrays.SparseMatrixCSC}","page":"operators","title":"Laplacians.wtedEdgeVertexMat","text":"U = wtedEdgeVertexMat(a)\n\nThe signed and weighted edge-vertex adjacency matrix, so U'*U = L\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Unexported-(Private)-functions.-1","page":"Private Functions","title":"Unexported (Private) functions.","text":"","category":"section"},{"location":"privateFuncs/#","page":"Private Functions","title":"Private Functions","text":"This is a list of all unexported functions and types from Laplacians.","category":"page"},{"location":"privateFuncs/#","page":"Private Functions","title":"Private Functions","text":"Pages   = [\"privateFuncs.md\"]","category":"page"},{"location":"privateFuncs/#","page":"Private Functions","title":"Private Functions","text":"Public = false\nModules = [Laplacians]","category":"page"},{"location":"privateFuncs/#Laplacians.ApproxCholPQ","page":"Private Functions","title":"Laplacians.ApproxCholPQ","text":"An approximate priority queue.   Items are bundled together into doubly-linked lists with all approximately the same key.   minlist is the min list we know to be non-empty.   It should always be a lower bound.   keyMap maps keys to lists\n\n\n\n\n\n","category":"type"},{"location":"privateFuncs/#Laplacians.IJV-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"Private Functions","title":"Laplacians.IJV","text":"ijv = IJV(A::SparseMatrixCSC)\n\nConvert a sparse matrix to an IJV.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.LDLinv","page":"Private Functions","title":"Laplacians.LDLinv","text":"LDLinv contains the information needed to solve the Laplacian systems.   It does it by applying Linv, then Dinv, then Linv (transpose).   But, it is specially constructed for this particular solver.   It does not explicitly make the matrix triangular.   Rather, col[i] is the name of the ith col to be eliminated\n\n\n\n\n\n","category":"type"},{"location":"privateFuncs/#Laplacians.LLmatp","page":"Private Functions","title":"Laplacians.LLmatp","text":"LLmatp is the data structure used to maintain the matrix during elimination.   It stores the elements in each column in a singly linked list (only next ptrs)   Each element is an LLp (linked list pointer).   The head of each column is pointed to by cols.\n\nWe probably can get rid of degs - as it is only used to store initial degrees.\n\n\n\n\n\n","category":"type"},{"location":"privateFuncs/#Laplacians.LLp","page":"Private Functions","title":"Laplacians.LLp","text":"LLp elements are all in the same column.   row tells us the row, and val is the entry.   val is set to zero for some edges that we should remove.   next gives the next in the column.  It points to itself to terminate.   reverse is the index into lles of the other copy of this edge,   since every edge is stored twice as we do not know the order of elimination in advance.\n\n\n\n\n\n","category":"type"},{"location":"privateFuncs/#Laplacians.approxCholPQDec!-Union{Tuple{Tind}, Tuple{Laplacians.ApproxCholPQ{Tind}, Any}} where Tind","page":"Private Functions","title":"Laplacians.approxCholPQDec!","text":"Decrement the key of element i\nThis could crash if i exceeds the maxkey\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.approxCholPQInc!-Union{Tuple{Tind}, Tuple{Laplacians.ApproxCholPQ{Tind}, Any}} where Tind","page":"Private Functions","title":"Laplacians.approxCholPQInc!","text":"Increment the key of element i\nThis could crash if i exceeds the maxkey\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.approxchol_lapChol-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"Private Functions","title":"Laplacians.approxchol_lapChol","text":"This variation of approxChol creates a cholesky factor to do the elimination. It has not yet been optimized, and does not yet make the cholesky factor lower triangular\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.augmentTreeOpt-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, SparseArrays.SparseMatrixCSC{Tv, Ti}}} where {Tv, Ti}","page":"Private Functions","title":"Laplacians.augmentTreeOpt","text":"B = augmentTreeOpt{Tv,Ti}(tree, A, params)\n\nTakes as input a tree and an adjacency matrix of a graph. It then computes the stretch of every edge of the graph wrt the tree.  It uses cholmod to decide how many edge to add back, shooting for nnzLfac times n entries in the factored augmented tree, with a number of flops to factor equal to nnz(a)*flopsfac. The edges to add back are then choen at random.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.blockSolver-Tuple{Any, Any}","page":"Private Functions","title":"Laplacians.blockSolver","text":"Apply the ith solver on the ith component\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.complete_bipartite_graph_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.complete_bipartite_graph_ijv","text":"ijv = complete_bipartite_graph_ijv(n)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.complete_graph_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.complete_graph_ijv","text":"ijv = complete_graph_ijv(n)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.empty_graph_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.empty_graph_ijv","text":"ijv = empty_graph_ijv(n)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.extendMatrix-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Tv}, Vector{Tv}}} where {Tv, Ti}","page":"Private Functions","title":"Laplacians.extendMatrix","text":"Add a new vertex to a with weights to the other vertices corresponding to diagonal surplus weight.\n\nThis is an efficient way of writing [a d; d' 0]\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.firstn-Tuple{Laplacians.IJV, Integer}","page":"Private Functions","title":"Laplacians.firstn","text":"b = firstn(a::IJV, n::Integer)\n\nOnly keep the first n vertices of a.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.forceLap-Tuple{AbstractArray}","page":"Private Functions","title":"Laplacians.forceLap","text":"la = forceLap(a)\n\nCreate a Laplacian matrix from an adjacency matrix. If the input looks like a Laplacian, throw a warning and convert it.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.generalizedNecklace-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, SparseArrays.SparseMatrixCSC, Int64}} where {Tv, Ti}","page":"Private Functions","title":"Laplacians.generalizedNecklace","text":"graph = generalizedNecklace(A, H, k::Int64)\n\nConstructs a generalized necklace graph starting with two graphs A and H. The resulting new graph will be constructed by expanding each vertex in H to an instance of A. k random edges will be generated between components. Thus, the resulting graph may have weighted edges.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.initDictCol!-Tuple{Any, Any, Any}","page":"Private Functions","title":"Laplacians.initDictCol!","text":"initDictCol!(dic, name, typ)\n\nFor a dictionary in which each key indexes an array. If dic does not contain an entry of name, create with set to Array(typ,0).\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.lapWrapComponents-Tuple{Any, AbstractArray}","page":"Private Functions","title":"Laplacians.lapWrapComponents","text":"f = lapWrapComponents(solver, a::AbstractArray; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[], params...)\n\nApplies a Laplacian solver that satisfies our interface to each connected component of the graph with adjacency matrix a. Passes kwargs on the solver.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.lapWrapConnected-Tuple{Any, AbstractMatrix}","page":"Private Functions","title":"Laplacians.lapWrapConnected","text":"f = lapWrapConnected(sddmSolver, a::AbstractMatrix; kwargs...)\n\nApplies a sddmSolver to the Laplacian of the adjacency matrix a of a connected graph. Passes on kwargs to the solver. sddmSolver should be a solver that obeys the interface.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.ldli2Chol-Tuple{Any}","page":"Private Functions","title":"Laplacians.ldli2Chol","text":"L = ldli2Chol(ldli)\n\nThis produces a matrix L so that L L^T approximate the original Laplacians. It is not quite a Cholesky factor, because it is off by a perm (and the all-1s vector orthogonality.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.path_graph_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.path_graph_ijv","text":"ijv = path_graph_ijv(n::Int64)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.print_ll_col-Tuple{Laplacians.LLMatOrd, Int64}","page":"Private Functions","title":"Laplacians.print_ll_col","text":"Print a column in an LLMatOrd matrix.   This is here for diagnostics.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.print_ll_col-Tuple{Laplacians.LLmatp, Int64}","page":"Private Functions","title":"Laplacians.print_ll_col","text":"Print a column in an LLmatp matrix.   This is here for diagnostics.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.pure_random_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.pure_random_ijv","text":"a = pure_random_ijv(n::Integer; verbose=false, prefix=\"\", ver=Vcur)\n\nChooses among pathgraph, ringgraph, gridgraph, completebinarytree, randgenring, growngraph and ErdosRenyiClusterFix. It can produce a disconnected graph. For code that always produces a connected graph (and is the same as with Julia v0.6, use purerandomijv_v6)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.pushSpeedResult!-Tuple{Any, Any, Any}","page":"Private Functions","title":"Laplacians.pushSpeedResult!","text":"ret is the answer returned by a speed test. This pushed it into the dictionary on which we are storing the tests.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.rand_regular_bipartite-Tuple{Any, Any}","page":"Private Functions","title":"Laplacians.rand_regular_bipartite","text":"a = rand_regular_bipartite(n,k)\n\nRandom k-regular bipartite graph between two sets of n vertices. No repeat edges, so can take a long time to build of k is close to n.\n\nReturns a (possibly) asymmetric matrix that contains the upper-right block.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.ring_graph_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.ring_graph_ijv","text":"ijv = ring_graph_ijv(n)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.sampleByWeight-Tuple{Any}","page":"Private Functions","title":"Laplacians.sampleByWeight","text":"ind = sampleByWeight(wt; ver=Vcur)\n\nsample an index with probability proportional to its weight given here\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.sddmWrapLap-Tuple{Any, AbstractArray}","page":"Private Functions","title":"Laplacians.sddmWrapLap","text":"f = sddmWrapLap(lapSolver, sddm::AbstractArray; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[], params...)\n\nUses a lapSolver to solve systems of linear equations in sddm matrices.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.sortSet-Union{Tuple{Ti}, Tuple{Vector{Ti}, Ti}} where Ti","page":"Private Functions","title":"Laplacians.sortSet","text":"Given a set of integers, set between 1 and n, return a sorted version of them\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.star_graph_ijv-Tuple{Integer}","page":"Private Functions","title":"Laplacians.star_graph_ijv","text":"ijv = star_graph_ijv(n::Int64)\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.testZeroDiag-Tuple{Any}","page":"Private Functions","title":"Laplacians.testZeroDiag","text":"testZeroDiag(a)\n\nReturns true if a has zero diagonal, false otherwise\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.treeDepthDFS-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}}, Tuple{Ti}, Tuple{Tv}} where {Tv, Ti}","page":"Private Functions","title":"Laplacians.treeDepthDFS","text":"Compute the vector of depths in a tree that is in DFS order, with the root at the first position, and the leaves at the end\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.uniformWeight_ver-Tuple{Type{Val{6}}, SparseArrays.SparseMatrixCSC}","page":"Private Functions","title":"Laplacians.uniformWeight_ver","text":"wted = uniformWeight(unwted)\n\nPut a uniform [0,1] weight on every edge.  This is an example of how to use mapweight.\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.wrapCapture-Tuple{Function, Any, Any}","page":"Private Functions","title":"Laplacians.wrapCapture","text":"f = wrapCapture(solver::Function, mats, rhss; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[], params...)\n\nThis wraps a solver so that we can capture all the matrices that it solves and all the right-hand-sides. Those are pushed into the arrays mats and rhss. For example\n\njulia> mats = []\njulia> rhss = []\njulia> solver = wrapCapture(approxchol_lap, mats, rhss)\njulia> a = chimera(10)\njulia> f = solver(a);\njulia> size(mats[1])\n(10,10)\njulia> b = randn(10)\njulia> x = f(b);\njulia> rhss\n1-element Array{Any,1}:\n [0.404962,-0.827718,0.704616,-0.403223,0.204891,-0.505589,0.907015,1.90266,-0.438115,0.0464351]\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.wrapCaptureRhs-Tuple{Function, Any}","page":"Private Functions","title":"Laplacians.wrapCaptureRhs","text":"f = wrapCaptureRhs(sola::Function, rhss; tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[], params...)\n\nCaptures all the right-hand-sides that are passed to the solver sola.  It pushes them into an array called rhhs. For example\n\njulia> rhss = []\njulia> a = wted_chimera(100)\njulia> sola = approxchol_lap(a)\njulia> wrappedSolver = wrapCaptureRhs(sola,rhss)\njulia> b = randn(100)\njulia> x = wrappedSolver(b,verbose=true)\n\nPCG BLAS stopped after: 0.0 seconds and 11 iterations with relative error 3.160275810360986e-7.\n\njulia> length(rhss[1])\n\n100\n\n\n\n\n\n","category":"method"},{"location":"privateFuncs/#Laplacians.wrapInterface-Tuple{Function, AbstractMatrix}","page":"Private Functions","title":"Laplacians.wrapInterface","text":"solveA = wrapInterface(solver::Function, A::AbstractMatrix; tol, maxits, maxtime, verbose, pcgIts=Int[],params...)\nsolverConstructor = wrapInterface(A::AbstractMatrix; tol, maxits, maxtime, verbose, pcgIts=Int[],params...)\n\nReturns a function that discards tol, maxits, maxtime and verbose, sets pcgIts to 0 (because it might not be using pcg), and passes whatever params are left to the solver.\n\nExamples\n\njulia> a = randn(5,5);\njulia> a = a * a';\njulia> solvea = wrapInterface(X->cholesky(X,Val(true)), a, maxits=100, verbose=true);\njulia> b = randn(5,1);\njulia> norm(a*solvea(b, verbose=false)-b)\n1.575705319704736e-14\n\njulia> f = wrapInterface(X->cholesky(X,Val(true)))\njulia> solvea = f(a, maxits=1000, maxtime = 1)\njulia> norm(a*solvea(b, verbose=false, maxtime = 10)-b)\n1.575705319704736e-14\n\n\n\n\n\n","category":"method"},{"location":"#Laplacians.jl-1","page":"About","title":"Laplacians.jl","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Laplacians is a package containing graph algorithms, with an emphasis on tasks related to spectral and algebraic graph theory. It contains (and will contain more) code for solving systems of linear equations in graph Laplacians, low stretch spanning trees, sparsifiation, clustering, local clustering, and optimization on graphs.","category":"page"},{"location":"#","page":"About","title":"About","text":"All graphs are represented by sparse adjacency matrices. This is both for speed, and because our main concerns are algebraic tasks. It does not handle dynamic graphs. It would be very slow to implement dynamic graphs this way.","category":"page"},{"location":"#","page":"About","title":"About","text":"The documentation may be found by clicking the \"docs\" link above.","category":"page"},{"location":"#","page":"About","title":"About","text":"This includes instructions for installing Julia, and some tips for how to start using it.  It also includes guidelines for Dan Spielman's collaborators.","category":"page"},{"location":"#","page":"About","title":"About","text":"For some examples of some of the things you can do with Laplacians, look at","category":"page"},{"location":"#","page":"About","title":"About","text":"this Julia notebook.\nLow Stretch Spanning Trees\nInformation about solving Laplacian equations\nAn example of sparsification\nAnd, try the chimera and wtedChimera graph generators.  They are designed to generate a wide variety of graphs so as to exercise code.","category":"page"},{"location":"#","page":"About","title":"About","text":"If you want to solve Laplacian equations, we recommend approxchol_lap.","category":"page"},{"location":"#","page":"About","title":"About","text":"The algorithms provide by Laplacians.jl include:","category":"page"},{"location":"#","page":"About","title":"About","text":"akpw, a heuristic for computing low stretch spanning trees written by Daniel Spielman, inspired by the algorithm from the paper \"A graph-theoretic game and its application to the k-server problem\" by Alon, Karp, Peleg, and West, <i>SIAM Journal on Computing</i>, 1995.\napproxchol_lap: a fast heuristic for solving Laplacians equations written by Yuan Gao, Rasmus Kyng, and Daniel Spielman. It is described in the paper \"Robust and Practical Solution of Laplacian Equations by Approximate Elimination\" (https://arxiv.org/abs/2303.00709). The solver is based on  \"Approximate Gaussian Elimination for Laplacians: Fast, Sparse, and Simple\" by Rasmus Kyng and Sushant Sachdeva, FOCS 2016.   For SDDM systems, use approxchol_sddm.\nharmonic_interp: Harmonic Interpolation on graphs.  Minimizes the Laplacians quadratic form subject to fixing values at certain vertices.\nsparsify, an implementation of sparsification by effective resistance sampling, following Spielman and Srivastava.\nKMPLapSolver and KMPSDDSolver: linear equation solvers based on the paper \"Approaching optimality for solving SDD systems\" by Koutis, Miller, and Peng, <i>SIAM Journal on Computing</i>, 2014.\nsamplingSDDSolver and samplingLapSolver, based on the paper \"Approximate Gaussian Elimination for Laplacians: Fast, Sparse, and Simple\" by Rasmus Kyng and Sushant Sachdeva, FOCS 2016.\nchimera and wted_chimera graph generators for testing graph algorithms, by Daniel Spielman.\nLocal Graph Clustering Heuristics, implemented by Serban Stan, including prn a version of PageRank Nibble based on \"Using PageRank to Locally Partition a Graph\", <i>Internet Mathematics</i> and LocalImprove based on \"Flow-Based Algorithms for Local Graph Clustering\" by Zeyuan Allen-Zhu and Lorenzo Orecchia, SODA 2014.","category":"page"},{"location":"#Current-Development-Version-1","page":"About","title":"Current Development Version","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"To get the current version of the master branch, run pkg> add Laplacians#master","category":"page"},{"location":"#Version-1.4.0-1","page":"About","title":"Version 1.4.0","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Contains the revised approximate Cholesky preconditioner described in the forthcoming paper by Gao, Kyng, and Spielman.","category":"page"},{"location":"#Version-1.3.0-1","page":"About","title":"Version 1.3.0","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This is compatible with Julia 1.7. The only significant change from 1.2.0 was dictated by a change in interface to SuiteSparse.","category":"page"},{"location":"#Version-1.2.0-1","page":"About","title":"Version 1.2.0","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This version is compatible with Julia 1.4, 1.5, and 1.6. but not earlier versions. Some features of this version will break in Julia 1.7.","category":"page"},{"location":"#","page":"About","title":"About","text":"Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Added two graph generators: complete_bipartite_graph, star_graph.\nAdded a function line_graph that computes the line graph of an input graph.","category":"page"},{"location":"#Version-1.1.1-1","page":"About","title":"Version 1.1.1","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Change: minor bug fix for spectral graph drawing.","category":"page"},{"location":"#","page":"About","title":"About","text":"Verified compatibility with Julia 1.2.","category":"page"},{"location":"#Version-1.1.0-1","page":"About","title":"Version 1.1.0","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Updating to use Julia's new Registrator.\nAdded harmonic_interp to interpolate harmonic functions on graphs.  This is the fundamental routine used in Label Propagation / Semi-Supervised Learning on Graphs.\nAdded a function read_graph to replace readIJ and readIJV.  It is a little more robust.\nCleaned up maxflow so that it now returns a flow and cut as a matrix and set.\nMade pcg a little more general.\nAdded fiedler for computing Fiedler vectors and values.  That is, the smallest nonzero eigenvalue of the Laplacian.\nFixed a bug in thicken that could cause it to loop forever, and cause chimera to do the same.\nChanged the graph drawing code to use Plots instead of PyPlot.","category":"page"},{"location":"#Version-1.0.1-1","page":"About","title":"Version 1.0.1","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Added latin_square_graph and latin_square.\nAllow plot_graph to plot in 3D.\nFixed performance bug due to lazy matrix transpose.\nChanged more function names to agree with Julia naming conventions.\nUpdate documentation and examples.","category":"page"},{"location":"#Version-1.0.0-1","page":"About","title":"Version 1.0.0","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This version works with Julia version 1.0.0.","category":"page"},{"location":"#Verson-0.3.1-1","page":"About","title":"Verson 0.3.1","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"The major change in this version is to the chimera and wted_chimera graph generators.  They are now faster, and incorporate two-lifts and thickening.  The old versions, using the pseudorandom generator from Julia V0.6 and Versions 0.2 of Laplacians, may be accessed by using the flag ver=Laplacians.V06, as in\na = chimera(2000, 1, ver=Laplacians.V06)\nThere do seem to be differences in the very low order bits of graphs generated by wted_chimera with the V06 option and those generated in Julia V0.6.  Not sure why.\nThe old generator is obtained by using the RandomV06 package for Julia.\nChanged the names of many functions to bring closer to the Julia standard naming scheme.  New names are emptygraph, pathgraph, ringgraph, completegraph, generalizedring, randgenring, productgraph, joingraphs, twolift ...  Set deprecation warnings for the old names.\nMoved lex.jl to the directory buggy, as on further testing we found bugs in it.\ndropped wGrid3, as it produced a 4d grid so probably wasn't being used anyway.  Dropped wGrid2 also.","category":"page"},{"location":"#Version-0.3.0,-July-18-(or-so),-2017-1","page":"About","title":"Version 0.3.0, July 18 (or so), 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This is the first version that is compatible with Julia 0.7.  Other changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Dropped support for samplingSDDM and samplingLap solvers.\nThe behavior of rand in Julia 0.7 is different, and this has changed the behavior of chimera.  So, the chimera graphs generated in Version 0.3.0 and beyond will be different from those before.","category":"page"},{"location":"#Version-0.2.2,-December-28,-2017-1","page":"About","title":"Version 0.2.2, December 28, 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Fixed two bugs: one in shortestPaths, and one that prevented passing some parameters to approxchol_sddm.  Improved the documentation for solving linear equations.","category":"page"},{"location":"#Version-0.2.1,-September-18,-2017-1","page":"About","title":"Version 0.2.1, September 18, 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Fixed a bug in approxchol_sddm that caused it to be slow.","category":"page"},{"location":"#Version-0.2.0,-July-17,-2017-1","page":"About","title":"Version 0.2.0, July 17, 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This version is compatabile with Julia 0.6.  It will not work with Julia 0.5.X.","category":"page"},{"location":"#","page":"About","title":"About","text":"Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Added approxchol_sddm, a wrapper of approxchol_lap that solves SDDM systems.","category":"page"},{"location":"#Version-0.1.4,-June-6,-2017-1","page":"About","title":"Version 0.1.4, June 6, 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This is the current version.  It is what you retrieve when you run Pkg.add(\"Laplacians\").","category":"page"},{"location":"#","page":"About","title":"About","text":"Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Added sparsify, an implementation of sparsification by effective resistance sampling, following Spielman and Srivastava.\nAdded approxQual and conditionNumber for checking how well one graph approximates another.\nFixed a bug in the solution of Laplacian systems in disconnected graphs.","category":"page"},{"location":"#Version-0.1.3,-June-2,-2017-1","page":"About","title":"Version 0.1.3, June 2, 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Major Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"Changed the name of the approximate Cholesky solver from edgeElimLap to approxchol_lap.  Made improvements in this solver.\nImproved PCG so that it can now detect stagnation.  Made options to do this even better when using it with a good preconditioner, like approxchol_lap.\nAdded in code for comparing the running times of solvers.  The difficulty here is that we need to stop them if they run too long.  Added code to do this with threads inside Julia, and with gtimeout when calling Matlab to use icc, CMG, or LAMG.","category":"page"},{"location":"#Version-0.1.2,-April-2,-2017-1","page":"About","title":"Version 0.1.2, April 2, 2017","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This is the current version.  It is what you retrieve when you run Pkg.add(\"Laplacians\").","category":"page"},{"location":"#","page":"About","title":"About","text":"Major Changes:","category":"page"},{"location":"#","page":"About","title":"About","text":"added edgeElimLap - a fast Laplacian solver.\nfixed a bug in the unweighted version of akpw.","category":"page"},{"location":"#Version-0.1.1,-December-26,-2016-1","page":"About","title":"Version 0.1.1, December 26, 2016","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Changelist:","category":"page"},{"location":"#","page":"About","title":"About","text":"All of the linear equation solvers now have the same interface, and the Laplacian solvers work for disconnected graphs.\nSome support for calling solvers from Matlab has been added.\nDocumentation is now through Documenter.jl.","category":"page"},{"location":"#Version-0.0.3-/-0.1.0,-November-20,-2016-1","page":"About","title":"Version 0.0.3 / 0.1.0, November 20, 2016","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"Versions 0.0.3 and 0.1.0 are the same. These versions works with Julia 0.5.","category":"page"},{"location":"#","page":"About","title":"About","text":"Warning: the behavior of chimera and wtedChimera differs between Julia 0.4 and Julia 0.5 because randperm acts differently in these.","category":"page"},{"location":"#Version-0.0.2,-November-19,-2016-1","page":"About","title":"Version 0.0.2, November 19, 2016","text":"","category":"section"},{"location":"#","page":"About","title":"About","text":"This is the version that works with Julia 0.4. It was captured right before the upgrade to Julia 0.5","category":"page"},{"location":"localClustering/#Local-Clustering-1","page":"localClustering","title":"Local Clustering","text":"","category":"section"},{"location":"localClustering/#","page":"localClustering","title":"localClustering","text":"This is a collection of clustering related algorithms,   based on Approximate Personal PageRank, and improvement by local   flow computations.   It needs more documentation.","category":"page"},{"location":"localClustering/#","page":"localClustering","title":"localClustering","text":"For now, see the Local Clustering Notebook","category":"page"},{"location":"localClustering/#","page":"localClustering","title":"localClustering","text":"Pages   = [\"localClustering.md\"]","category":"page"},{"location":"localClustering/#","page":"localClustering","title":"localClustering","text":"Modules = [Laplacians]\nPages   = [\"cutHeuristics.jl\",\"localClustering.jl\"]","category":"page"},{"location":"localClustering/#Laplacians.dumbRefineCut-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.dumbRefineCut","text":"Modify a cluster by passing through all the vertices exactly once and \nadding/removing them based on the value of (Deg_external - Deg_Internal).\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.refineCut-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.refineCut","text":"Modify a cluster by adding or removing vertices by picking at each step \nthe vertex that has the maximum value of (Deg_external - Deg_Internal).\nEach vertex can be added in/removed only once.\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.apr-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}, Float64, Float64}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.apr","text":"Computes an approximate page rank vector from a starting set s, an alpha and an epsilon The algorithm follows the Anderson,Chung,Lang paper and Dan Spielman's lecture notes\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.localImprove-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.localImprove","text":"localImprove{Tv,Ti}(G::SparseMatrixCSC{Tv,Ti}, A::Array{Int64,1}; epsSigma=-1.0, err=1e-10, maxSize = max(G.n, G.m)\n\nThe LocalImprove function, from the Orrechia-Zhu paper. Given a graph and an initial set, finds a set of smaller conductance based on the starting set using a localized version of max-flow.\n\nSmall discussion: When adding in the neighbors of the initial component, if the resulting  conductance is worse than the initial one,  the algorithm will add more and more vertices until hitting a better conductance. However, if we fix a certain  maximum size for our component,  it might be the case that this new conductance will always be worse than what we had initially. Thus, if we run the algorithm with a small maxSize,  our initial conductance might be the best solution we can raech.\n\nG is the given graph, A is the initial set \nepsSigma is a measure of the quality of the returning set (the smaller the better). It's defaulted to volume(A) / volume(V - A)\nerr is the numerical error considered throughout the algorithm. It's defaulted to 1e-10\nmaxSize is the maximum allowed size for the flow graph at any iteration of the algorithm. It's defaulted to |V|\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.prn-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}, Float64, Int64}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.prn","text":"prn{Tv, Ti}(G::SparseMatrixCSC{Tv,Ti}, s::Array{Int64,1}, phi::Float64, b::Int64)\n\nThe PageRank-Nibble cutting algorithm from the Anderson/Chung/Lang paper\n\ns is a set of starting vertices, phi is a constant in (0, 1], and b is an integer in [1, [log m]]\n\nphi is a bound on the quality of the conductance of the cut - the smaller the phi, the higher the quality.  b is used to handle precision throughout the algorithm - the higher the b, the greater the precision.\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.addToGPrime-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Vector{Tuple{Int64, Float64}}}, Dict{Int64, Int64}, Dict{Int64, Int64}, Int64, Int64, Float64, Float64, Int64}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.addToGPrime","text":"Add a new vertex to GPrime \n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.getCutSet-Tuple{Vector{Vector{Tuple{Int64, Float64}}}, Int64, Int64}","page":"localClustering","title":"Laplacians.getCutSet","text":"Get the min cut from the source - return all vertices in the cut besides the source \n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.initGPrime-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}, Dict{Int64, Int64}, Dict{Int64, Int64}, Float64, Int64}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.initGPrime","text":"Initialize GPrime with the set A and edges of type s->u\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.localBlockFlow-Tuple{Vector{Vector{Tuple{Int64, Float64}}}, Int64, Int64}","page":"localClustering","title":"Laplacians.localBlockFlow","text":"Compute block flow between s and t\n\n\n\n\n\n","category":"method"},{"location":"localClustering/#Laplacians.localFlow-Union{Tuple{Ti}, Tuple{Tv}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}, Float64, Float64}, Tuple{SparseArrays.SparseMatrixCSC{Tv, Ti}, Vector{Int64}, Float64, Float64, Any}} where {Tv, Ti}","page":"localClustering","title":"Laplacians.localFlow","text":"The LocalFlow function, from the Orecchia-Zhu paper \n\n\n\n\n\n","category":"method"},{"location":"Installation/#Installation-1","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Caveat: These instructions are old (circa Julia 0.5)  The same ideas apply, but they need updating.  You can probably find a better reference now. ","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Before you can use Laplacians, you need Julia. So, we'll begin with instructions for installing Julia.  I (Dan S.) found that it worked best if I installed Python first.  So, I'll suggest that you do the same.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"All of these instruction assume you are using a Mac. ","category":"page"},{"location":"Installation/#Python-1","page":"Installation","title":"Python","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Install python.  I recommend the anaconda distribution https://www.continuum.io/downloads.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Once you install python, you are going to want two packages: a plotting package that Julia will use, and jupyter notebooks for interacting with Julia.  Install them like","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"conda install matplotlib\nconda install mathjax\nconda install jupyter","category":"page"},{"location":"Installation/#Julia-1","page":"Installation","title":"Julia","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"You can get Julia from  http://julialang.org/.   If you are using a Mac, you may wish to create a symnolic link to the Julia executable so that you can call it from a terminal.  For example, you can do this like:","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"cd /usr/local/bin/\nln -s julia /Applications/Julia-0.5.app/Contents/Resources/julia/bin/julia","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Once you have this, you will want Julia notebooks.  To install this, run julia and type","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"julia> Pkg.add(\"IJulia\")\njulia> using IJulia","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"This will install the package, and put the current julia kernel into jupyter.  In the future, you can launch the Julia notebook by typing (in a terminal)","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"jupyter notebook","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Most users will also want to install PyPlot, if you did not already. To do that, type","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Pkg.add(\"PyPlot\")","category":"page"},{"location":"Installation/#Laplacians-1","page":"Installation","title":"Laplacians","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"In theory, all you need to do now is type either","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"julia> Pkg.add(\"Laplacians\")","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"To use the package, you then type","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"julia> using Laplacians","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The one catch is with the functions for drawing graphs.  These require PyPlot.  If you did not install it before typing Pkg.add(\"PyPlot\"), then you can either install it now or disable the plotting routines in Laplacians.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"If you do not want to load PyPlot, then either set the environment variable LAPLACIANS_NOPLOT to true in bash, like","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"$ export LAPLACIANS_NOPLOT=true","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"or, set the variable inside Julia, like ","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"julia> LAPLACIANS_NOPLOT = true","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"before typing using Laplacians. Similarly, you can avoid loading PyAmg by setting","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"julia> LAPLACIANS_NOAMG = true","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"(note that these are not the same variable: the environment variable in Julia is available as ENV[\"LAPLACIANS_NOPLOT\"]. Actually, defining these variables to anything will have the same effect.  So, setting them to false has the same effect as setting them to true.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"To see if Laplacians is working, try typing","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"a = chimera(100,6)\nspectral_drawing(a)","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"or","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"a = generalizedNecklace(grid2(6),grid2(3),2)\nspectral_drawing(a)","category":"page"}]
}
